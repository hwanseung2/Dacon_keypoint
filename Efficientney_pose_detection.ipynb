{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "british-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_utils\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# For image-keypoints data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sustainable-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value) \n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\\n\n",
    "        torch.backends.cudnn.deterministic = True  #needed\\n\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "random_seed(seed,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "closing-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"train_imgs\")\n",
    "num_classes = 48\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "num_splits = 10\n",
    "num_earlystop = 10\n",
    "input_w_crop = 1080\n",
    "input_h_crop = 1080\n",
    "input_w_resize = 150\n",
    "input_h_resize = 150\n",
    "learning_rate = 0.01\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaningful-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_palm_x</th>\n",
       "      <th>right_palm_y</th>\n",
       "      <th>spine2(back)_x</th>\n",
       "      <th>spine2(back)_y</th>\n",
       "      <th>spine1(waist)_x</th>\n",
       "      <th>spine1(waist)_y</th>\n",
       "      <th>left_instep_x</th>\n",
       "      <th>left_instep_y</th>\n",
       "      <th>right_instep_x</th>\n",
       "      <th>right_instep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-1-1-01-Z17_A-0000001.jpg</td>\n",
       "      <td>1046.389631</td>\n",
       "      <td>344.757881</td>\n",
       "      <td>1041.655294</td>\n",
       "      <td>329.820225</td>\n",
       "      <td>1059.429507</td>\n",
       "      <td>334.484230</td>\n",
       "      <td>1020.117796</td>\n",
       "      <td>338.890539</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1019.484230</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>1026.515770</td>\n",
       "      <td>514.054730</td>\n",
       "      <td>998.578836</td>\n",
       "      <td>826.718013</td>\n",
       "      <td>1063.204067</td>\n",
       "      <td>838.827465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-1-1-01-Z17_A-0000003.jpg</td>\n",
       "      <td>1069.850679</td>\n",
       "      <td>340.711494</td>\n",
       "      <td>1058.608552</td>\n",
       "      <td>324.593690</td>\n",
       "      <td>1075.242111</td>\n",
       "      <td>325.593690</td>\n",
       "      <td>1041.422997</td>\n",
       "      <td>331.694815</td>\n",
       "      <td>1065.593682</td>\n",
       "      <td>...</td>\n",
       "      <td>1081.187380</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>1046.953248</td>\n",
       "      <td>454.062706</td>\n",
       "      <td>1058.766231</td>\n",
       "      <td>508.797029</td>\n",
       "      <td>1002.265676</td>\n",
       "      <td>699.062706</td>\n",
       "      <td>1066.376234</td>\n",
       "      <td>841.499445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1-1-01-Z17_A-0000005.jpg</td>\n",
       "      <td>1084.475902</td>\n",
       "      <td>337.000008</td>\n",
       "      <td>1078.717997</td>\n",
       "      <td>323.757889</td>\n",
       "      <td>1095.648412</td>\n",
       "      <td>325.242119</td>\n",
       "      <td>1061.039884</td>\n",
       "      <td>329.351571</td>\n",
       "      <td>1086.461032</td>\n",
       "      <td>...</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>1044.538960</td>\n",
       "      <td>442.054730</td>\n",
       "      <td>1052.844144</td>\n",
       "      <td>495.890539</td>\n",
       "      <td>989.437847</td>\n",
       "      <td>808.757889</td>\n",
       "      <td>1066.071417</td>\n",
       "      <td>841.749554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-1-1-01-Z17_A-0000007.jpg</td>\n",
       "      <td>1042.320047</td>\n",
       "      <td>361.452689</td>\n",
       "      <td>1037.907194</td>\n",
       "      <td>344.117804</td>\n",
       "      <td>1050.328382</td>\n",
       "      <td>353.913729</td>\n",
       "      <td>1016.844144</td>\n",
       "      <td>340.913737</td>\n",
       "      <td>1042.164191</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.406318</td>\n",
       "      <td>372.461040</td>\n",
       "      <td>982.937294</td>\n",
       "      <td>458.109462</td>\n",
       "      <td>990.375124</td>\n",
       "      <td>507.624866</td>\n",
       "      <td>1001.305177</td>\n",
       "      <td>829.233767</td>\n",
       "      <td>1159.516499</td>\n",
       "      <td>599.389997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-1-1-01-Z17_A-0000009.jpg</td>\n",
       "      <td>1058.046395</td>\n",
       "      <td>343.164191</td>\n",
       "      <td>1046.717997</td>\n",
       "      <td>331.703163</td>\n",
       "      <td>1058.132650</td>\n",
       "      <td>331.781079</td>\n",
       "      <td>1031.258806</td>\n",
       "      <td>338.593690</td>\n",
       "      <td>1049.812620</td>\n",
       "      <td>...</td>\n",
       "      <td>1069.648429</td>\n",
       "      <td>334.109461</td>\n",
       "      <td>1024.843791</td>\n",
       "      <td>453.687572</td>\n",
       "      <td>1034.391088</td>\n",
       "      <td>510.843791</td>\n",
       "      <td>998.625231</td>\n",
       "      <td>805.218921</td>\n",
       "      <td>1059.625956</td>\n",
       "      <td>839.765102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image       nose_x      nose_y   left_eye_x  \\\n",
       "0  001-1-1-01-Z17_A-0000001.jpg  1046.389631  344.757881  1041.655294   \n",
       "1  001-1-1-01-Z17_A-0000003.jpg  1069.850679  340.711494  1058.608552   \n",
       "2  001-1-1-01-Z17_A-0000005.jpg  1084.475902  337.000008  1078.717997   \n",
       "3  001-1-1-01-Z17_A-0000007.jpg  1042.320047  361.452689  1037.907194   \n",
       "4  001-1-1-01-Z17_A-0000009.jpg  1058.046395  343.164191  1046.717997   \n",
       "\n",
       "   left_eye_y  right_eye_x  right_eye_y   left_ear_x  left_ear_y  right_ear_x  \\\n",
       "0  329.820225  1059.429507   334.484230  1020.117796  338.890539  1048.000000   \n",
       "1  324.593690  1075.242111   325.593690  1041.422997  331.694815  1065.593682   \n",
       "2  323.757889  1095.648412   325.242119  1061.039884  329.351571  1086.461032   \n",
       "3  344.117804  1050.328382   353.913729  1016.844144  340.913737  1042.164191   \n",
       "4  331.703163  1058.132650   331.781079  1031.258806  338.593690  1049.812620   \n",
       "\n",
       "   ...  right_palm_x  right_palm_y  spine2(back)_x  spine2(back)_y  \\\n",
       "0  ...   1067.000000    335.000000     1019.484230      455.000000   \n",
       "1  ...   1081.187380    323.000000     1046.953248      454.062706   \n",
       "2  ...   1101.000000    334.000000     1044.538960      442.054730   \n",
       "3  ...   1057.406318    372.461040      982.937294      458.109462   \n",
       "4  ...   1069.648429    334.109461     1024.843791      453.687572   \n",
       "\n",
       "   spine1(waist)_x  spine1(waist)_y  left_instep_x  left_instep_y  \\\n",
       "0      1026.515770       514.054730     998.578836     826.718013   \n",
       "1      1058.766231       508.797029    1002.265676     699.062706   \n",
       "2      1052.844144       495.890539     989.437847     808.757889   \n",
       "3       990.375124       507.624866    1001.305177     829.233767   \n",
       "4      1034.391088       510.843791     998.625231     805.218921   \n",
       "\n",
       "   right_instep_x  right_instep_y  \n",
       "0     1063.204067      838.827465  \n",
       "1     1066.376234      841.499445  \n",
       "2     1066.071417      841.749554  \n",
       "3     1159.516499      599.389997  \n",
       "4     1059.625956      839.765102  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"train_df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trained-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = df.iloc[:, 0].to_numpy()\n",
    "motions = df.iloc[:, 1:]\n",
    "columns = motions.columns.to_list()[::2]\n",
    "class_labels = [label.replace('_x', '').replace('_y', '') for label in columns]\n",
    "keypoints = []\n",
    "for motion in motions.to_numpy():\n",
    "    a_keypoints = []\n",
    "    for i in range(0, motion.shape[0], 2):\n",
    "        a_keypoints.append((float(motion[i]), float(motion[i+1])))\n",
    "    keypoints.append(a_keypoints)\n",
    "keypoints = np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, earlystop=0, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    earlystop_value = 0\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_loss = 999999999\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_since = time.time()\n",
    "        if earlystop and earlystop_value >= earlystop:\n",
    "            break\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        #print('outputs.shape, aux_outputs shape : ', outputs.shape, aux_outputs.shape)\n",
    "                        loss1 = criterion(outputs.float(), labels.float())\n",
    "                        loss2 = criterion(aux_outputs.float(), labels.float())\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        #print('output shape : ', outputs.shape)\n",
    "                        #print(outputs)\n",
    "                        loss = criterion(outputs.float(), labels.float())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # for regression\n",
    "                running_corrects += torch.sum(outputs == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            epoch_time_elapsed = time.time() - epoch_since\n",
    "            print('{} ({}) Loss: {:.4f} Acc: {:.4f} Elapsed time: {:.0f}m {:.0f}s'.format(\n",
    "                phase, len(dataloaders[phase].dataset), epoch_loss, epoch_acc, epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "#             neptune.log_metric(f'{phase}_loss', epoch_loss)\n",
    "#             neptune.log_metric(f'{phase}_acc', epoch_acc)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    earlystop_value = 0\n",
    "                else:\n",
    "                    earlystop_value += 1\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training and Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best validation Acc: {:4f}\\n'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {'acc': val_acc_history, 'loss': val_loss_history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seven-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposed-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (7): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (10): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (13): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (14): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (16): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (17): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (18): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (19): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (20): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (21): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (22): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (23): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (24): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (25): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (26): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (27): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (28): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (29): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (30): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (31): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (32): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (33): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (34): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (35): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (36): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (37): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (38): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (_fc): Linear(in_features=2048, out_features=48, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'efficientnet'\n",
    "model_ver = 'b5'\n",
    "def initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # variables is model specific.\n",
    "#     model_ft = getattr(models, f'{model_name}{model_ver}')(pretrained=use_pretrained)\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b5')\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_ftrs = model._fc.in_features\n",
    "    model._fc = nn.Linear(num_ftrs, num_classes)\n",
    "    #print(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft = initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acoustic-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transforms = {\n",
    "    'train':\n",
    "        A.Compose([\n",
    "            #A.augmentations.CenterCrop(input_h_crop, input_w_crop, always_apply = True),\n",
    "            A.Resize(input_h_resize, input_w_resize, always_apply=True),\n",
    "            A.OneOf([A.HorizontalFlip(p=1),\n",
    "                     A.RandomRotate90(p=1),\n",
    "                     A.VerticalFlip(p=1)            \n",
    "            ], p=0.5),\n",
    "            A.augmentations.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
    "    \n",
    "    'val':\n",
    "        A.Compose([\n",
    "            #A.augmentations.CenterCrop(input_h_crop, input_w_crop, always_apply = True),\n",
    "            A.Resize(input_h_resize, input_w_resize, always_apply=True),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
    "    \n",
    "    'test':\n",
    "        A.Compose([\n",
    "            #A.augmentations.CenterCrop(input_h_crop, input_w_crop, always_apply = True),\n",
    "            A.Resize(input_h_resize, input_w_resize, always_apply=True),\n",
    "            #A.augmentations.CenterCrop(input_h, input_w, always_apply = True),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "assumed-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data_utils.Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "    def __init__(self, data_dir, imgs, keypoints, phase, class_labels=None, data_transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.imgs = imgs\n",
    "        self.keypoints = keypoints\n",
    "        self.phase = phase\n",
    "        self.class_labels = class_labels\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read an image with OpenCV\n",
    "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
    "        keypoints = self.keypoints[idx]\n",
    "    \n",
    "        if self.data_transforms:\n",
    "            augmented = self.data_transforms[self.phase](image=img, keypoints=keypoints, class_labels=self.class_labels)\n",
    "            img = augmented['image']\n",
    "            keypoints = augmented['keypoints']\n",
    "        keypoints = np.array(keypoints).flatten()\n",
    "\n",
    "        return img, keypoints\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "leading-uniform",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "----------\n",
      "train (3775) Loss: 1029.3379 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 2791566420338.5903 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 2/200\n",
      "----------\n",
      "train (3775) Loss: 287.3443 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 3341.8122 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 3/200\n",
      "----------\n",
      "train (3775) Loss: 281.3969 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 1120.8145 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 4/200\n",
      "----------\n",
      "train (3775) Loss: 197.3174 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 327.9382 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 5/200\n",
      "----------\n",
      "train (3775) Loss: 150.5113 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 309.8846 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 6/200\n",
      "----------\n",
      "train (3775) Loss: 108.9102 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 658.2343 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 7/200\n",
      "----------\n",
      "train (3775) Loss: 75.8436 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 607.1483 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 8/200\n",
      "----------\n",
      "train (3775) Loss: 60.9899 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 615.9691 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 9/200\n",
      "----------\n",
      "train (3775) Loss: 60.8655 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 434.7425 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 10/200\n",
      "----------\n",
      "train (3775) Loss: 55.9907 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 329.1283 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 11/200\n",
      "----------\n",
      "train (3775) Loss: 53.6844 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 349.2327 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 12/200\n",
      "----------\n",
      "train (3775) Loss: 50.5820 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 119.5821 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 13/200\n",
      "----------\n",
      "train (3775) Loss: 46.1200 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 164.5129 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 14/200\n",
      "----------\n",
      "train (3775) Loss: 48.4776 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 98.3986 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 15/200\n",
      "----------\n",
      "train (3775) Loss: 47.9437 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 253.9654 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 16/200\n",
      "----------\n",
      "train (3775) Loss: 45.4857 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 142.4086 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 17/200\n",
      "----------\n",
      "train (3775) Loss: 43.9340 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 264.7794 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 18/200\n",
      "----------\n",
      "train (3775) Loss: 43.9232 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 253.9894 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 19/200\n",
      "----------\n",
      "train (3775) Loss: 43.6907 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 198.3103 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 20/200\n",
      "----------\n",
      "train (3775) Loss: 41.7812 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 140.6022 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 21/200\n",
      "----------\n",
      "train (3775) Loss: 39.7107 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 69.6411 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 22/200\n",
      "----------\n",
      "train (3775) Loss: 42.3076 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 139.7951 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 23/200\n",
      "----------\n",
      "train (3775) Loss: 39.0566 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 174.8702 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 24/200\n",
      "----------\n",
      "train (3775) Loss: 37.7822 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 162.5947 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 25/200\n",
      "----------\n",
      "train (3775) Loss: 40.2600 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 146.9161 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 26/200\n",
      "----------\n",
      "train (3775) Loss: 38.0488 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 70.9023 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 27/200\n",
      "----------\n",
      "train (3775) Loss: 38.1778 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 226.0720 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 28/200\n",
      "----------\n",
      "train (3775) Loss: 38.0849 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 58.8194 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 29/200\n",
      "----------\n",
      "train (3775) Loss: 36.9118 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 220.8334 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 30/200\n",
      "----------\n",
      "train (3775) Loss: 41.1356 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 1070.7032 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 31/200\n",
      "----------\n",
      "train (3775) Loss: 39.3261 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 520.7871 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 32/200\n",
      "----------\n",
      "train (3775) Loss: 36.7781 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 247.0249 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 33/200\n",
      "----------\n",
      "train (3775) Loss: 34.6841 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 541.5543 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 34/200\n",
      "----------\n",
      "train (3775) Loss: 34.1802 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 168.8483 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 35/200\n",
      "----------\n",
      "train (3775) Loss: 32.0462 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 112.0295 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 36/200\n",
      "----------\n",
      "train (3775) Loss: 35.2101 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 550.1881 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 37/200\n",
      "----------\n",
      "train (3775) Loss: 37.7370 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 229.8774 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 38/200\n",
      "----------\n",
      "train (3775) Loss: 32.4227 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 176.3114 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 39/200\n",
      "----------\n",
      "train (3775) Loss: 31.2402 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 625.7811 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 40/200\n",
      "----------\n",
      "train (3775) Loss: 32.1810 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 266.6689 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 41/200\n",
      "----------\n",
      "train (3775) Loss: 28.6072 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 124.4553 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 42/200\n",
      "----------\n",
      "train (3775) Loss: 30.3762 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 161.5438 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 43/200\n",
      "----------\n",
      "train (3775) Loss: 30.5319 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 246.3779 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 44/200\n",
      "----------\n",
      "train (3775) Loss: 29.8402 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 743.1437 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 45/200\n",
      "----------\n",
      "train (3775) Loss: 27.9280 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 152.4794 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 46/200\n",
      "----------\n",
      "train (3775) Loss: 27.8546 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 328.4951 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 47/200\n",
      "----------\n",
      "train (3775) Loss: 25.9760 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 147.0337 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 48/200\n",
      "----------\n",
      "train (3775) Loss: 27.2217 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 93.0306 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 49/200\n",
      "----------\n",
      "train (3775) Loss: 27.2407 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 238.4279 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 50/200\n",
      "----------\n",
      "train (3775) Loss: 27.6464 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 129.0344 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 51/200\n",
      "----------\n",
      "train (3775) Loss: 27.5423 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 127.8798 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 52/200\n",
      "----------\n",
      "train (3775) Loss: 27.6456 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 130.4501 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 53/200\n",
      "----------\n",
      "train (3775) Loss: 27.5082 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 280.1395 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 54/200\n",
      "----------\n",
      "train (3775) Loss: 26.5489 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 175.3807 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 55/200\n",
      "----------\n",
      "train (3775) Loss: 26.0410 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 243.5822 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 56/200\n",
      "----------\n",
      "train (3775) Loss: 26.1907 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 266.5854 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 57/200\n",
      "----------\n",
      "train (3775) Loss: 26.6781 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 424.0239 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 58/200\n",
      "----------\n",
      "train (3775) Loss: 23.3364 Acc: 0.0000 Elapsed time: 1m 47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val (420) Loss: 254.8461 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 59/200\n",
      "----------\n",
      "train (3775) Loss: 25.9070 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 180.8850 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 60/200\n",
      "----------\n",
      "train (3775) Loss: 23.4361 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 56.5660 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 61/200\n",
      "----------\n",
      "train (3775) Loss: 27.1091 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 381.9173 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 62/200\n",
      "----------\n",
      "train (3775) Loss: 25.3400 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 117.1434 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 63/200\n",
      "----------\n",
      "train (3775) Loss: 26.1530 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 148.0341 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 64/200\n",
      "----------\n",
      "train (3775) Loss: 23.9159 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 296.7568 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 65/200\n",
      "----------\n",
      "train (3775) Loss: 24.0124 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 142.5554 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 66/200\n",
      "----------\n",
      "train (3775) Loss: 25.4442 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 186.5592 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 67/200\n",
      "----------\n",
      "train (3775) Loss: 24.8265 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 101.5754 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 68/200\n",
      "----------\n",
      "train (3775) Loss: 24.2942 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 128.7717 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 69/200\n",
      "----------\n",
      "train (3775) Loss: 22.1592 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 235.8073 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 70/200\n",
      "----------\n",
      "train (3775) Loss: 22.7346 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 98.4341 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 71/200\n",
      "----------\n",
      "train (3775) Loss: 22.6856 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 172.9814 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 72/200\n",
      "----------\n",
      "train (3775) Loss: 21.6733 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 144.3537 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 73/200\n",
      "----------\n",
      "train (3775) Loss: 21.4962 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 223.8334 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 74/200\n",
      "----------\n",
      "train (3775) Loss: 19.6608 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 234.9062 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 75/200\n",
      "----------\n",
      "train (3775) Loss: 20.8363 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 69.7388 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 76/200\n",
      "----------\n",
      "train (3775) Loss: 21.1209 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 61.7793 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 77/200\n",
      "----------\n",
      "train (3775) Loss: 22.3046 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 106.5663 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 78/200\n",
      "----------\n",
      "train (3775) Loss: 22.5018 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 143.0485 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 79/200\n",
      "----------\n",
      "train (3775) Loss: 20.3154 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 188.5964 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 80/200\n",
      "----------\n",
      "train (3775) Loss: 21.8333 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 293.4618 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 81/200\n",
      "----------\n",
      "train (3775) Loss: 21.5914 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 67.9141 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 82/200\n",
      "----------\n",
      "train (3775) Loss: 21.4876 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 149.3450 Acc: 0.0000 Elapsed time: 1m 59s\n",
      "\n",
      "Epoch 83/200\n",
      "----------\n",
      "train (3775) Loss: 19.8158 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 89.3803 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 84/200\n",
      "----------\n",
      "train (3775) Loss: 20.9294 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 73.7327 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 85/200\n",
      "----------\n",
      "train (3775) Loss: 21.3262 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 140.7972 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 86/200\n",
      "----------\n",
      "train (3775) Loss: 19.7998 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 46.7397 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 87/200\n",
      "----------\n",
      "train (3775) Loss: 21.4693 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 210.3120 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 88/200\n",
      "----------\n",
      "train (3775) Loss: 22.9481 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 211.4567 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 89/200\n",
      "----------\n",
      "train (3775) Loss: 19.9526 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 72.5254 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 90/200\n",
      "----------\n",
      "train (3775) Loss: 19.9457 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 85.2836 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 91/200\n",
      "----------\n",
      "train (3775) Loss: 21.2702 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 339.3712 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 92/200\n",
      "----------\n",
      "train (3775) Loss: 21.3506 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 501.0358 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 93/200\n",
      "----------\n",
      "train (3775) Loss: 19.7891 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 166.6512 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 94/200\n",
      "----------\n",
      "train (3775) Loss: 18.9235 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 209.6505 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 95/200\n",
      "----------\n",
      "train (3775) Loss: 19.0851 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 191.2148 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 96/200\n",
      "----------\n",
      "train (3775) Loss: 19.5122 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 93.3850 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 97/200\n",
      "----------\n",
      "train (3775) Loss: 19.4042 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 114.3254 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 98/200\n",
      "----------\n",
      "train (3775) Loss: 18.6355 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 101.5695 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 99/200\n",
      "----------\n",
      "train (3775) Loss: 17.6324 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 60.4635 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 100/200\n",
      "----------\n",
      "train (3775) Loss: 17.4916 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 250.9753 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 101/200\n",
      "----------\n",
      "train (3775) Loss: 18.0552 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 229.4142 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 102/200\n",
      "----------\n",
      "train (3775) Loss: 17.6117 Acc: 0.0003 Elapsed time: 1m 52s\n",
      "val (420) Loss: 153.9254 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 103/200\n",
      "----------\n",
      "train (3775) Loss: 18.0087 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 40.7812 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 104/200\n",
      "----------\n",
      "train (3775) Loss: 17.4237 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 41.5288 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 105/200\n",
      "----------\n",
      "train (3775) Loss: 17.5058 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 35.3064 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 106/200\n",
      "----------\n",
      "train (3775) Loss: 16.1536 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 20.4698 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 107/200\n",
      "----------\n",
      "train (3775) Loss: 16.6373 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 160.3452 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 108/200\n",
      "----------\n",
      "train (3775) Loss: 17.8563 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 46.9642 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 109/200\n",
      "----------\n",
      "train (3775) Loss: 17.3324 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 164.6721 Acc: 0.0000 Elapsed time: 2m 1s\n",
      "\n",
      "Epoch 110/200\n",
      "----------\n",
      "train (3775) Loss: 16.6975 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 171.7725 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 111/200\n",
      "----------\n",
      "train (3775) Loss: 16.0137 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 44.1032 Acc: 0.0000 Elapsed time: 2m 1s\n",
      "\n",
      "Epoch 112/200\n",
      "----------\n",
      "train (3775) Loss: 15.8820 Acc: 0.0000 Elapsed time: 1m 52s\n",
      "val (420) Loss: 43.8855 Acc: 0.0000 Elapsed time: 2m 2s\n",
      "\n",
      "Epoch 113/200\n",
      "----------\n",
      "train (3775) Loss: 15.9584 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 109.2646 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 114/200\n",
      "----------\n",
      "train (3775) Loss: 18.3066 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 123.4768 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 115/200\n",
      "----------\n",
      "train (3775) Loss: 19.6254 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 323.9936 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 116/200\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3775) Loss: 21.6289 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 221.7986 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 117/200\n",
      "----------\n",
      "train (3775) Loss: 18.3476 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 97.1325 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 118/200\n",
      "----------\n",
      "train (3775) Loss: 22.8314 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 108.3508 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 119/200\n",
      "----------\n",
      "train (3775) Loss: 18.6671 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 56.5682 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 120/200\n",
      "----------\n",
      "train (3775) Loss: 17.5402 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 100.5540 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 121/200\n",
      "----------\n",
      "train (3775) Loss: 17.3893 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 48.4228 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 122/200\n",
      "----------\n",
      "train (3775) Loss: 16.7989 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 117.6697 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 123/200\n",
      "----------\n",
      "train (3775) Loss: 16.2021 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 104.6015 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 124/200\n",
      "----------\n",
      "train (3775) Loss: 17.0657 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 210.4405 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 125/200\n",
      "----------\n",
      "train (3775) Loss: 16.3478 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 109.3439 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 126/200\n",
      "----------\n",
      "train (3775) Loss: 17.2816 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 72.2693 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 127/200\n",
      "----------\n",
      "train (3775) Loss: 19.4396 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 301.0615 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 128/200\n",
      "----------\n",
      "train (3775) Loss: 19.4102 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 213.4818 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 129/200\n",
      "----------\n",
      "train (3775) Loss: 18.3692 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 121.2076 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 130/200\n",
      "----------\n",
      "train (3775) Loss: 18.2955 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 89.1863 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 131/200\n",
      "----------\n",
      "train (3775) Loss: 17.4853 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 64.3346 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 132/200\n",
      "----------\n",
      "train (3775) Loss: 17.5169 Acc: 0.0003 Elapsed time: 1m 49s\n",
      "val (420) Loss: 34.8191 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 133/200\n",
      "----------\n",
      "train (3775) Loss: 15.4744 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 32.1673 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 134/200\n",
      "----------\n",
      "train (3775) Loss: 15.6271 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 13.5976 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 135/200\n",
      "----------\n",
      "train (3775) Loss: 15.5515 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 52.7064 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 136/200\n",
      "----------\n",
      "train (3775) Loss: 15.4280 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 70.8256 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 137/200\n",
      "----------\n",
      "train (3775) Loss: 14.7087 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 53.8612 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 138/200\n",
      "----------\n",
      "train (3775) Loss: 15.0688 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 42.6721 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 139/200\n",
      "----------\n",
      "train (3775) Loss: 14.7742 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 73.6495 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 140/200\n",
      "----------\n",
      "train (3775) Loss: 14.1901 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 55.6421 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 141/200\n",
      "----------\n",
      "train (3775) Loss: 15.1507 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 121.3784 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 142/200\n",
      "----------\n",
      "train (3775) Loss: 14.3538 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 16.3195 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 143/200\n",
      "----------\n",
      "train (3775) Loss: 15.1390 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 25.8669 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 144/200\n",
      "----------\n",
      "train (3775) Loss: 15.3648 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 41.0315 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 145/200\n",
      "----------\n",
      "train (3775) Loss: 14.2557 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 123.8103 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 146/200\n",
      "----------\n",
      "train (3775) Loss: 16.1621 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 198.4775 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 147/200\n",
      "----------\n",
      "train (3775) Loss: 18.4748 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 195.1225 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 148/200\n",
      "----------\n",
      "train (3775) Loss: 15.9015 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 126.3686 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 149/200\n",
      "----------\n",
      "train (3775) Loss: 15.0895 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 19.0563 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 150/200\n",
      "----------\n",
      "train (3775) Loss: 15.4442 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 97.2399 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 151/200\n",
      "----------\n",
      "train (3775) Loss: 15.7115 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 115.2789 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 152/200\n",
      "----------\n",
      "train (3775) Loss: 15.2105 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 37.5793 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 153/200\n",
      "----------\n",
      "train (3775) Loss: 15.6677 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 50.4359 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 154/200\n",
      "----------\n",
      "train (3775) Loss: 15.2289 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 64.5051 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 155/200\n",
      "----------\n",
      "train (3775) Loss: 14.3942 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 51.0129 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 156/200\n",
      "----------\n",
      "train (3775) Loss: 14.3848 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 43.2872 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 157/200\n",
      "----------\n",
      "train (3775) Loss: 15.0490 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 66.1599 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 158/200\n",
      "----------\n",
      "train (3775) Loss: 14.3650 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 88.6489 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 159/200\n",
      "----------\n",
      "train (3775) Loss: 13.9233 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 51.0875 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 160/200\n",
      "----------\n",
      "train (3775) Loss: 13.6803 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 10.9563 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 161/200\n",
      "----------\n",
      "train (3775) Loss: 14.8311 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 64.3161 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 162/200\n",
      "----------\n",
      "train (3775) Loss: 15.7503 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 261.3302 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 163/200\n",
      "----------\n",
      "train (3775) Loss: 15.3922 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 158.8948 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 164/200\n",
      "----------\n",
      "train (3775) Loss: 16.2756 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 176.6384 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 165/200\n",
      "----------\n",
      "train (3775) Loss: 14.5541 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 57.4151 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 166/200\n",
      "----------\n",
      "train (3775) Loss: 14.7253 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 69.2058 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 167/200\n",
      "----------\n",
      "train (3775) Loss: 15.4873 Acc: 0.0000 Elapsed time: 1m 48s\n",
      "val (420) Loss: 33.1586 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 168/200\n",
      "----------\n",
      "train (3775) Loss: 15.1085 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 110.5478 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 169/200\n",
      "----------\n",
      "train (3775) Loss: 14.7660 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 92.2413 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 170/200\n",
      "----------\n",
      "train (3775) Loss: 14.3992 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 11.2804 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 171/200\n",
      "----------\n",
      "train (3775) Loss: 14.4468 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 45.3794 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 172/200\n",
      "----------\n",
      "train (3775) Loss: 13.8088 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 27.0564 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 173/200\n",
      "----------\n",
      "train (3775) Loss: 13.1837 Acc: 0.0000 Elapsed time: 1m 48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val (420) Loss: 16.6314 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Epoch 174/200\n",
      "----------\n",
      "train (3775) Loss: 13.1994 Acc: 0.0003 Elapsed time: 1m 47s\n",
      "val (420) Loss: 10.9717 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 175/200\n",
      "----------\n",
      "train (3775) Loss: 14.0300 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 191.7811 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 176/200\n",
      "----------\n",
      "train (3775) Loss: 14.1286 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 88.3020 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 177/200\n",
      "----------\n",
      "train (3775) Loss: 13.1051 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 20.4839 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 178/200\n",
      "----------\n",
      "train (3775) Loss: 12.7973 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 28.1324 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 179/200\n",
      "----------\n",
      "train (3775) Loss: 12.2519 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 16.8719 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 180/200\n",
      "----------\n",
      "train (3775) Loss: 13.3424 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 45.3725 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 181/200\n",
      "----------\n",
      "train (3775) Loss: 12.5782 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 36.9654 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 182/200\n",
      "----------\n",
      "train (3775) Loss: 14.1244 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 44.8357 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 183/200\n",
      "----------\n",
      "train (3775) Loss: 13.4901 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 20.0274 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 184/200\n",
      "----------\n",
      "train (3775) Loss: 12.8943 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 47.6231 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 185/200\n",
      "----------\n",
      "train (3775) Loss: 13.1501 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 23.5014 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 186/200\n",
      "----------\n",
      "train (3775) Loss: 12.4611 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 12.0543 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 187/200\n",
      "----------\n",
      "train (3775) Loss: 12.9047 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 104.2123 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 188/200\n",
      "----------\n",
      "train (3775) Loss: 13.5303 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 20.8516 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 189/200\n",
      "----------\n",
      "train (3775) Loss: 13.6255 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 20.8231 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 190/200\n",
      "----------\n",
      "train (3775) Loss: 12.9103 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 15.5057 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 191/200\n",
      "----------\n",
      "train (3775) Loss: 13.9187 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 83.8334 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 192/200\n",
      "----------\n",
      "train (3775) Loss: 14.0169 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 55.0488 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 193/200\n",
      "----------\n",
      "train (3775) Loss: 14.3898 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 12.4940 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 194/200\n",
      "----------\n",
      "train (3775) Loss: 15.3916 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 110.7680 Acc: 0.0000 Elapsed time: 1m 59s\n",
      "\n",
      "Epoch 195/200\n",
      "----------\n",
      "train (3775) Loss: 13.5453 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 53.6815 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 196/200\n",
      "----------\n",
      "train (3775) Loss: 13.4036 Acc: 0.0000 Elapsed time: 1m 49s\n",
      "val (420) Loss: 50.1829 Acc: 0.0000 Elapsed time: 1m 58s\n",
      "\n",
      "Epoch 197/200\n",
      "----------\n",
      "train (3775) Loss: 12.8091 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 18.3759 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 198/200\n",
      "----------\n",
      "train (3775) Loss: 13.6772 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 26.0522 Acc: 0.0000 Elapsed time: 1m 56s\n",
      "\n",
      "Epoch 199/200\n",
      "----------\n",
      "train (3775) Loss: 13.5702 Acc: 0.0000 Elapsed time: 1m 50s\n",
      "val (420) Loss: 64.0363 Acc: 0.0000 Elapsed time: 1m 59s\n",
      "\n",
      "Epoch 200/200\n",
      "----------\n",
      "train (3775) Loss: 12.4260 Acc: 0.0000 Elapsed time: 1m 47s\n",
      "val (420) Loss: 15.2550 Acc: 0.0000 Elapsed time: 1m 57s\n",
      "\n",
      "Training and Validation complete in 389m 8s\n",
      "Best validation Acc: 0.000000\n",
      "\n",
      "Elapsed time: 389m 9s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "since = time.time()\n",
    "X_train, X_val, y_train, y_val = train_test_split(imgs, keypoints, test_size=1/num_splits, random_state=42)\n",
    "train_data = Dataset(train_dir, X_train, y_train, data_transforms=A_transforms, class_labels=class_labels, phase='train')\n",
    "val_data = Dataset(train_dir, X_val, y_val, data_transforms=A_transforms, class_labels=class_labels, phase='val')\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data_utils.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hists = train_model(\n",
    "    model_ft, dataloaders, criterion, optimizer_ft,\n",
    "    num_epochs=num_epochs,  is_inception=(model_name==\"inception\"))\n",
    "weight_path = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\", f\"baseline_{model_name}_{model_ver}_0312.pth\")\n",
    "torch.save(model_ft.state_dict(), weight_path)\n",
    "time_elapsed = time.time() - since\n",
    "print('Elapsed time: {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "invalid-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3775 420\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pediatric-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(type(hists['loss']))\n",
    "losses = np.array([])\n",
    "\n",
    "for loss in hists['loss']:\n",
    "    losses = np.append(losses, loss)\n",
    "\n",
    "plt.plot(losses[20:])\n",
    "plt.show()\n",
    "#200 epoch 6hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "urban-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "horizontal-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = f'{prefix}/data/test_imgs'\n",
    "test_dir = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"test_imgs\")\n",
    "test_imgs = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "guilty-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data_utils.Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "    def __init__(self, data_dir, imgs, phase, data_transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.imgs = imgs\n",
    "        self.phase = phase\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.imgs[idx]\n",
    "        # Read an image with OpenCV\n",
    "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
    "\n",
    "        if self.data_transforms:\n",
    "            augmented = self.data_transforms[self.phase](image=img)\n",
    "            img = augmented['image']\n",
    "        return filename, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "test_data = TestDataset(test_dir, test_imgs, data_transforms=A_transforms, phase='test')\n",
    "test_loader = data_utils.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "auburn-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "files = []\n",
    "with torch.no_grad():\n",
    "    for filenames, inputs in test_loader:\n",
    "        predictions = list(model_ft(inputs.to(device)).cpu().numpy())\n",
    "        files.extend(filenames)\n",
    "        for prediction in predictions:\n",
    "            all_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moral-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "for i in range(all_predictions.shape[0]):\n",
    "    all_predictions[i, [2*j for j in range(num_classes//2)]] /= input_w_resize / 1920\n",
    "    all_predictions[i, [2*j + 1 for j in range(num_classes//2)]] /= input_h_resize / 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "obvious-burner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_palm_x</th>\n",
       "      <th>right_palm_y</th>\n",
       "      <th>spine2(back)_x</th>\n",
       "      <th>spine2(back)_y</th>\n",
       "      <th>spine1(waist)_x</th>\n",
       "      <th>spine1(waist)_y</th>\n",
       "      <th>left_instep_x</th>\n",
       "      <th>left_instep_y</th>\n",
       "      <th>right_instep_x</th>\n",
       "      <th>right_instep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>649-2-4-32-Z148_A-0000001.jpg</td>\n",
       "      <td>1117.597656</td>\n",
       "      <td>530.090637</td>\n",
       "      <td>1123.552246</td>\n",
       "      <td>548.380798</td>\n",
       "      <td>1145.809082</td>\n",
       "      <td>542.808594</td>\n",
       "      <td>1103.622681</td>\n",
       "      <td>585.301086</td>\n",
       "      <td>1155.160889</td>\n",
       "      <td>...</td>\n",
       "      <td>1078.468872</td>\n",
       "      <td>313.608185</td>\n",
       "      <td>975.882202</td>\n",
       "      <td>557.902832</td>\n",
       "      <td>893.33905</td>\n",
       "      <td>550.480957</td>\n",
       "      <td>665.916565</td>\n",
       "      <td>700.954895</td>\n",
       "      <td>764.800659</td>\n",
       "      <td>664.596436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>649-2-4-32-Z148_A-0000003.jpg</td>\n",
       "      <td>1116.693604</td>\n",
       "      <td>530.937134</td>\n",
       "      <td>1122.715088</td>\n",
       "      <td>549.403687</td>\n",
       "      <td>1144.859619</td>\n",
       "      <td>543.786682</td>\n",
       "      <td>1102.488403</td>\n",
       "      <td>586.51355</td>\n",
       "      <td>1153.810303</td>\n",
       "      <td>...</td>\n",
       "      <td>1078.83374</td>\n",
       "      <td>313.711639</td>\n",
       "      <td>974.37439</td>\n",
       "      <td>558.418213</td>\n",
       "      <td>891.998413</td>\n",
       "      <td>550.734314</td>\n",
       "      <td>667.139282</td>\n",
       "      <td>700.570068</td>\n",
       "      <td>765.568665</td>\n",
       "      <td>663.787231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>649-2-4-32-Z148_A-0000005.jpg</td>\n",
       "      <td>1123.157959</td>\n",
       "      <td>540.511292</td>\n",
       "      <td>1132.065308</td>\n",
       "      <td>561.278931</td>\n",
       "      <td>1152.297607</td>\n",
       "      <td>555.952454</td>\n",
       "      <td>1111.440186</td>\n",
       "      <td>598.858459</td>\n",
       "      <td>1159.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1105.588867</td>\n",
       "      <td>283.618103</td>\n",
       "      <td>975.273071</td>\n",
       "      <td>559.171997</td>\n",
       "      <td>889.923523</td>\n",
       "      <td>547.340088</td>\n",
       "      <td>679.25177</td>\n",
       "      <td>697.950745</td>\n",
       "      <td>772.860474</td>\n",
       "      <td>657.198547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>649-2-4-32-Z148_A-0000007.jpg</td>\n",
       "      <td>1193.003906</td>\n",
       "      <td>573.79657</td>\n",
       "      <td>1206.830811</td>\n",
       "      <td>587.262634</td>\n",
       "      <td>1235.377197</td>\n",
       "      <td>578.070679</td>\n",
       "      <td>1172.275635</td>\n",
       "      <td>620.953491</td>\n",
       "      <td>1238.105225</td>\n",
       "      <td>...</td>\n",
       "      <td>1328.338135</td>\n",
       "      <td>539.834351</td>\n",
       "      <td>1003.806641</td>\n",
       "      <td>578.470276</td>\n",
       "      <td>905.018921</td>\n",
       "      <td>568.476013</td>\n",
       "      <td>625.768005</td>\n",
       "      <td>690.792542</td>\n",
       "      <td>768.779297</td>\n",
       "      <td>647.536316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>649-2-4-32-Z148_A-0000009.jpg</td>\n",
       "      <td>1136.396851</td>\n",
       "      <td>534.157043</td>\n",
       "      <td>1146.82373</td>\n",
       "      <td>558.716797</td>\n",
       "      <td>1169.981812</td>\n",
       "      <td>555.397583</td>\n",
       "      <td>1125.701172</td>\n",
       "      <td>600.335022</td>\n",
       "      <td>1180.824585</td>\n",
       "      <td>...</td>\n",
       "      <td>1141.395508</td>\n",
       "      <td>295.080475</td>\n",
       "      <td>981.003113</td>\n",
       "      <td>553.145996</td>\n",
       "      <td>889.610352</td>\n",
       "      <td>543.965881</td>\n",
       "      <td>665.572083</td>\n",
       "      <td>693.052429</td>\n",
       "      <td>777.77533</td>\n",
       "      <td>656.896118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image       nose_x      nose_y   left_eye_x  \\\n",
       "0  649-2-4-32-Z148_A-0000001.jpg  1117.597656  530.090637  1123.552246   \n",
       "1  649-2-4-32-Z148_A-0000003.jpg  1116.693604  530.937134  1122.715088   \n",
       "2  649-2-4-32-Z148_A-0000005.jpg  1123.157959  540.511292  1132.065308   \n",
       "3  649-2-4-32-Z148_A-0000007.jpg  1193.003906   573.79657  1206.830811   \n",
       "4  649-2-4-32-Z148_A-0000009.jpg  1136.396851  534.157043   1146.82373   \n",
       "\n",
       "   left_eye_y  right_eye_x right_eye_y   left_ear_x  left_ear_y  right_ear_x  \\\n",
       "0  548.380798  1145.809082  542.808594  1103.622681  585.301086  1155.160889   \n",
       "1  549.403687  1144.859619  543.786682  1102.488403   586.51355  1153.810303   \n",
       "2  561.278931  1152.297607  555.952454  1111.440186  598.858459  1159.699219   \n",
       "3  587.262634  1235.377197  578.070679  1172.275635  620.953491  1238.105225   \n",
       "4  558.716797  1169.981812  555.397583  1125.701172  600.335022  1180.824585   \n",
       "\n",
       "   ... right_palm_x right_palm_y spine2(back)_x spine2(back)_y  \\\n",
       "0  ...  1078.468872   313.608185     975.882202     557.902832   \n",
       "1  ...   1078.83374   313.711639      974.37439     558.418213   \n",
       "2  ...  1105.588867   283.618103     975.273071     559.171997   \n",
       "3  ...  1328.338135   539.834351    1003.806641     578.470276   \n",
       "4  ...  1141.395508   295.080475     981.003113     553.145996   \n",
       "\n",
       "  spine1(waist)_x spine1(waist)_y left_instep_x left_instep_y right_instep_x  \\\n",
       "0       893.33905      550.480957    665.916565    700.954895     764.800659   \n",
       "1      891.998413      550.734314    667.139282    700.570068     765.568665   \n",
       "2      889.923523      547.340088     679.25177    697.950745     772.860474   \n",
       "3      905.018921      568.476013    625.768005    690.792542     768.779297   \n",
       "4      889.610352      543.965881    665.572083    693.052429      777.77533   \n",
       "\n",
       "  right_instep_y  \n",
       "0     664.596436  \n",
       "1     663.787231  \n",
       "2     657.198547  \n",
       "3     647.536316  \n",
       "4     656.896118  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"sample_submission.csv\")\n",
    "df_sub = pd.read_csv(path)\n",
    "df = pd.DataFrame(columns=df_sub.columns)\n",
    "df['image'] = files\n",
    "df.iloc[:, 1:] = all_predictions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "electric-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"efficient_crop.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
