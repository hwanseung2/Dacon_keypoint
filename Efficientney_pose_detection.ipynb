{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "british-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_utils\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# For image-keypoints data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closing-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"train_imgs\")\n",
    "num_classes = 48\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "num_splits = 10\n",
    "num_earlystop = 10\n",
    "input_w = 150\n",
    "input_h = 150\n",
    "learning_rate = 0.01\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaningful-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_palm_x</th>\n",
       "      <th>right_palm_y</th>\n",
       "      <th>spine2(back)_x</th>\n",
       "      <th>spine2(back)_y</th>\n",
       "      <th>spine1(waist)_x</th>\n",
       "      <th>spine1(waist)_y</th>\n",
       "      <th>left_instep_x</th>\n",
       "      <th>left_instep_y</th>\n",
       "      <th>right_instep_x</th>\n",
       "      <th>right_instep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-1-1-01-Z17_A-0000001.jpg</td>\n",
       "      <td>1046.389631</td>\n",
       "      <td>344.757881</td>\n",
       "      <td>1041.655294</td>\n",
       "      <td>329.820225</td>\n",
       "      <td>1059.429507</td>\n",
       "      <td>334.484230</td>\n",
       "      <td>1020.117796</td>\n",
       "      <td>338.890539</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1019.484230</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>1026.515770</td>\n",
       "      <td>514.054730</td>\n",
       "      <td>998.578836</td>\n",
       "      <td>826.718013</td>\n",
       "      <td>1063.204067</td>\n",
       "      <td>838.827465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-1-1-01-Z17_A-0000003.jpg</td>\n",
       "      <td>1069.850679</td>\n",
       "      <td>340.711494</td>\n",
       "      <td>1058.608552</td>\n",
       "      <td>324.593690</td>\n",
       "      <td>1075.242111</td>\n",
       "      <td>325.593690</td>\n",
       "      <td>1041.422997</td>\n",
       "      <td>331.694815</td>\n",
       "      <td>1065.593682</td>\n",
       "      <td>...</td>\n",
       "      <td>1081.187380</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>1046.953248</td>\n",
       "      <td>454.062706</td>\n",
       "      <td>1058.766231</td>\n",
       "      <td>508.797029</td>\n",
       "      <td>1002.265676</td>\n",
       "      <td>699.062706</td>\n",
       "      <td>1066.376234</td>\n",
       "      <td>841.499445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1-1-01-Z17_A-0000005.jpg</td>\n",
       "      <td>1084.475902</td>\n",
       "      <td>337.000008</td>\n",
       "      <td>1078.717997</td>\n",
       "      <td>323.757889</td>\n",
       "      <td>1095.648412</td>\n",
       "      <td>325.242119</td>\n",
       "      <td>1061.039884</td>\n",
       "      <td>329.351571</td>\n",
       "      <td>1086.461032</td>\n",
       "      <td>...</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>1044.538960</td>\n",
       "      <td>442.054730</td>\n",
       "      <td>1052.844144</td>\n",
       "      <td>495.890539</td>\n",
       "      <td>989.437847</td>\n",
       "      <td>808.757889</td>\n",
       "      <td>1066.071417</td>\n",
       "      <td>841.749554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-1-1-01-Z17_A-0000007.jpg</td>\n",
       "      <td>1042.320047</td>\n",
       "      <td>361.452689</td>\n",
       "      <td>1037.907194</td>\n",
       "      <td>344.117804</td>\n",
       "      <td>1050.328382</td>\n",
       "      <td>353.913729</td>\n",
       "      <td>1016.844144</td>\n",
       "      <td>340.913737</td>\n",
       "      <td>1042.164191</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.406318</td>\n",
       "      <td>372.461040</td>\n",
       "      <td>982.937294</td>\n",
       "      <td>458.109462</td>\n",
       "      <td>990.375124</td>\n",
       "      <td>507.624866</td>\n",
       "      <td>1001.305177</td>\n",
       "      <td>829.233767</td>\n",
       "      <td>1159.516499</td>\n",
       "      <td>599.389997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-1-1-01-Z17_A-0000009.jpg</td>\n",
       "      <td>1058.046395</td>\n",
       "      <td>343.164191</td>\n",
       "      <td>1046.717997</td>\n",
       "      <td>331.703163</td>\n",
       "      <td>1058.132650</td>\n",
       "      <td>331.781079</td>\n",
       "      <td>1031.258806</td>\n",
       "      <td>338.593690</td>\n",
       "      <td>1049.812620</td>\n",
       "      <td>...</td>\n",
       "      <td>1069.648429</td>\n",
       "      <td>334.109461</td>\n",
       "      <td>1024.843791</td>\n",
       "      <td>453.687572</td>\n",
       "      <td>1034.391088</td>\n",
       "      <td>510.843791</td>\n",
       "      <td>998.625231</td>\n",
       "      <td>805.218921</td>\n",
       "      <td>1059.625956</td>\n",
       "      <td>839.765102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image       nose_x      nose_y   left_eye_x  \\\n",
       "0  001-1-1-01-Z17_A-0000001.jpg  1046.389631  344.757881  1041.655294   \n",
       "1  001-1-1-01-Z17_A-0000003.jpg  1069.850679  340.711494  1058.608552   \n",
       "2  001-1-1-01-Z17_A-0000005.jpg  1084.475902  337.000008  1078.717997   \n",
       "3  001-1-1-01-Z17_A-0000007.jpg  1042.320047  361.452689  1037.907194   \n",
       "4  001-1-1-01-Z17_A-0000009.jpg  1058.046395  343.164191  1046.717997   \n",
       "\n",
       "   left_eye_y  right_eye_x  right_eye_y   left_ear_x  left_ear_y  right_ear_x  \\\n",
       "0  329.820225  1059.429507   334.484230  1020.117796  338.890539  1048.000000   \n",
       "1  324.593690  1075.242111   325.593690  1041.422997  331.694815  1065.593682   \n",
       "2  323.757889  1095.648412   325.242119  1061.039884  329.351571  1086.461032   \n",
       "3  344.117804  1050.328382   353.913729  1016.844144  340.913737  1042.164191   \n",
       "4  331.703163  1058.132650   331.781079  1031.258806  338.593690  1049.812620   \n",
       "\n",
       "   ...  right_palm_x  right_palm_y  spine2(back)_x  spine2(back)_y  \\\n",
       "0  ...   1067.000000    335.000000     1019.484230      455.000000   \n",
       "1  ...   1081.187380    323.000000     1046.953248      454.062706   \n",
       "2  ...   1101.000000    334.000000     1044.538960      442.054730   \n",
       "3  ...   1057.406318    372.461040      982.937294      458.109462   \n",
       "4  ...   1069.648429    334.109461     1024.843791      453.687572   \n",
       "\n",
       "   spine1(waist)_x  spine1(waist)_y  left_instep_x  left_instep_y  \\\n",
       "0      1026.515770       514.054730     998.578836     826.718013   \n",
       "1      1058.766231       508.797029    1002.265676     699.062706   \n",
       "2      1052.844144       495.890539     989.437847     808.757889   \n",
       "3       990.375124       507.624866    1001.305177     829.233767   \n",
       "4      1034.391088       510.843791     998.625231     805.218921   \n",
       "\n",
       "   right_instep_x  right_instep_y  \n",
       "0     1063.204067      838.827465  \n",
       "1     1066.376234      841.499445  \n",
       "2     1066.071417      841.749554  \n",
       "3     1159.516499      599.389997  \n",
       "4     1059.625956      839.765102  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"train_df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "trained-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = df.iloc[:, 0].to_numpy()\n",
    "motions = df.iloc[:, 1:]\n",
    "columns = motions.columns.to_list()[::2]\n",
    "class_labels = [label.replace('_x', '').replace('_y', '') for label in columns]\n",
    "keypoints = []\n",
    "for motion in motions.to_numpy():\n",
    "    a_keypoints = []\n",
    "    for i in range(0, motion.shape[0], 2):\n",
    "        a_keypoints.append((float(motion[i]), float(motion[i+1])))\n",
    "    keypoints.append(a_keypoints)\n",
    "keypoints = np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agreed-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, earlystop=0, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    earlystop_value = 0\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_loss = 999999999\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_since = time.time()\n",
    "        if earlystop and earlystop_value >= earlystop:\n",
    "            break\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        print('outputs.shape, aux_outputs shape : ', outputs.shape, aux_outputs.shape)\n",
    "                        loss1 = criterion(outputs.float(), labels.float())\n",
    "                        loss2 = criterion(aux_outputs.float(), labels.float())\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        print('output shape : ', outputs.shape)\n",
    "                        print(outputs)\n",
    "                        loss = criterion(outputs.float(), labels.float())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # for regression\n",
    "                running_corrects += torch.sum(outputs == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            epoch_time_elapsed = time.time() - epoch_since\n",
    "            print('{} ({}) Loss: {:.4f} Acc: {:.4f} Elapsed time: {:.0f}m {:.0f}s'.format(\n",
    "                phase, len(dataloaders[phase].dataset), epoch_loss, epoch_acc, epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "#             neptune.log_metric(f'{phase}_loss', epoch_loss)\n",
    "#             neptune.log_metric(f'{phase}_acc', epoch_acc)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    earlystop_value = 0\n",
    "                else:\n",
    "                    earlystop_value += 1\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training and Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best validation Acc: {:4f}\\n'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {'acc': val_acc_history, 'loss': val_loss_history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seven-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposed-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (7): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (10): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (13): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (14): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (16): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (17): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (18): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (19): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (20): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (21): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (22): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (23): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (24): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (25): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (26): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (27): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (28): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (29): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (30): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (31): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (32): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (33): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (34): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (35): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (36): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (37): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (38): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (_fc): Linear(in_features=2048, out_features=48, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'efficientnet'\n",
    "model_ver = 'b5'\n",
    "def initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # variables is model specific.\n",
    "#     model_ft = getattr(models, f'{model_name}{model_ver}')(pretrained=use_pretrained)\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b5')\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_ftrs = model._fc.in_features\n",
    "    model._fc = nn.Linear(num_ftrs, num_classes)\n",
    "    #print(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft = initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acoustic-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transforms = {\n",
    "    'train':\n",
    "        A.Compose([\n",
    "            A.Resize(input_h, input_w, always_apply=True),\n",
    "            A.OneOf([A.HorizontalFlip(p=1),\n",
    "                     A.RandomRotate90(p=1),\n",
    "                     A.VerticalFlip(p=1)            \n",
    "            ], p=0.5),\n",
    "            A.OneOf([A.MotionBlur(p=1),\n",
    "                     A.GaussNoise(p=1)                 \n",
    "            ], p=0.5),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
    "    \n",
    "    'val':\n",
    "        A.Compose([\n",
    "            A.Resize(input_h, input_w, always_apply=True),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
    "    \n",
    "    'test':\n",
    "        A.Compose([\n",
    "            A.Resize(input_h, input_w, always_apply=True),\n",
    "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assumed-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data_utils.Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "    def __init__(self, data_dir, imgs, keypoints, phase, class_labels=None, data_transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.imgs = imgs\n",
    "        self.keypoints = keypoints\n",
    "        self.phase = phase\n",
    "        self.class_labels = class_labels\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read an image with OpenCV\n",
    "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
    "        keypoints = self.keypoints[idx]\n",
    "    \n",
    "        if self.data_transforms:\n",
    "            augmented = self.data_transforms[self.phase](image=img, keypoints=keypoints, class_labels=self.class_labels)\n",
    "            img = augmented['image']\n",
    "            keypoints = augmented['keypoints']\n",
    "        keypoints = np.array(keypoints).flatten()\n",
    "\n",
    "        return img, keypoints\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-0.0195,  0.2082,  0.0521,  ...,  0.1149,  0.1544, -0.0644],\n",
      "        [-0.0816, -0.0284, -0.0936,  ..., -0.3137, -0.1596, -0.1544],\n",
      "        [-0.0128, -0.1161, -0.2678,  ...,  0.2389,  0.3187, -0.1733],\n",
      "        ...,\n",
      "        [-0.0648,  0.2571, -0.1847,  ...,  0.0053, -0.0686,  0.1683],\n",
      "        [-0.0652,  0.0072, -0.0630,  ..., -0.3969,  0.3598, -0.1659],\n",
      "        [ 0.0233, -0.2680,  0.1070,  ..., -0.3193, -0.0344, -0.0630]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 0.4858,  0.3908,  0.6688,  ...,  0.8061,  0.7135,  0.9109],\n",
      "        [ 1.3177,  1.0937,  0.8080,  ...,  0.9237,  1.3598,  1.1174],\n",
      "        [ 0.4363,  0.6223,  0.2206,  ...,  0.9081,  0.8366,  0.6869],\n",
      "        ...,\n",
      "        [ 0.4631,  0.4165,  0.4280,  ...,  0.6220,  0.3384,  0.5771],\n",
      "        [ 0.4070,  0.2537,  0.2890,  ...,  0.0805,  0.5997, -0.0105],\n",
      "        [ 1.4201,  1.1407,  1.8481,  ...,  1.4836,  1.5940,  1.1203]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 4.9990,  4.0541,  4.6764,  ...,  4.7637,  4.4058,  5.0224],\n",
      "        [ 1.8137,  1.3178,  1.6868,  ...,  1.9308,  1.5304,  1.8267],\n",
      "        [ 1.1901,  1.4155,  1.3019,  ...,  0.8315,  1.3661,  0.9068],\n",
      "        ...,\n",
      "        [-1.5295, -1.3055, -1.5673,  ..., -1.2741, -1.5118, -1.3772],\n",
      "        [-0.6577, -0.8271, -0.9038,  ..., -0.5772, -0.8352, -0.3583],\n",
      "        [-2.5597, -2.1347, -2.2925,  ..., -2.2598, -2.5412, -2.2587]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 0.9790,  0.9388,  0.8796,  ...,  0.8270,  1.1410,  0.7208],\n",
      "        [23.8906, 22.8361, 23.7543,  ..., 22.2465, 24.2765, 22.9201],\n",
      "        [-5.4121, -4.7932, -5.2159,  ..., -5.1082, -5.3117, -5.0665],\n",
      "        ...,\n",
      "        [ 0.1838,  0.3160,  0.0846,  ...,  0.6277,  0.3441,  0.5164],\n",
      "        [ 3.7931,  3.3060,  3.5982,  ...,  3.4407,  3.5870,  3.3557],\n",
      "        [16.7342, 15.6854, 16.2544,  ..., 15.7158, 16.8173, 15.8531]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[11.7306, 11.6743, 11.5807,  ..., 10.9767, 11.9873, 10.9846],\n",
      "        [-0.8649, -0.5500, -0.7194,  ..., -0.8279, -0.6128, -0.8596],\n",
      "        [18.9549, 17.7835, 18.3747,  ..., 17.9213, 18.6570, 18.1157],\n",
      "        ...,\n",
      "        [23.2535, 22.3330, 22.8120,  ..., 21.6206, 22.9641, 21.9305],\n",
      "        [ 9.7630,  9.5119,  9.6768,  ...,  9.3631, 10.1482,  9.2948],\n",
      "        [40.1739, 38.3677, 39.4832,  ..., 38.4086, 40.1661, 38.5113]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[59.9357, 57.2568, 58.7892,  ..., 56.6650, 60.0714, 57.0262],\n",
      "        [ 5.3506,  5.4081,  5.3022,  ...,  4.7754,  5.5975,  5.0296],\n",
      "        [11.3850, 11.0872, 11.2021,  ..., 10.5624, 11.5685, 10.8792],\n",
      "        ...,\n",
      "        [48.6843, 46.0087, 47.7438,  ..., 46.8027, 48.2601, 46.5346],\n",
      "        [ 8.9111,  8.7160,  8.8474,  ...,  8.1797,  8.9829,  8.3150],\n",
      "        [65.2030, 61.7773, 63.9728,  ..., 61.4466, 63.8991, 62.0580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[17.5844, 16.8546, 17.5233,  ..., 17.2171, 17.5342, 17.3953],\n",
      "        [16.3769, 15.7475, 16.2605,  ..., 16.0649, 16.2071, 16.2848],\n",
      "        [ 9.4976,  9.1179,  9.6403,  ...,  9.3105,  9.4959,  9.4223],\n",
      "        ...,\n",
      "        [16.3840, 15.5782, 16.2684,  ..., 15.8990, 16.0775, 15.9533],\n",
      "        [23.9870, 22.3903, 23.6898,  ..., 23.7306, 23.5649, 23.5162],\n",
      "        [16.0810, 15.4936, 16.0434,  ..., 15.9816, 16.1187, 15.8255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[20.7346, 19.7593, 20.9428,  ..., 21.0244, 20.4762, 20.8916],\n",
      "        [21.2191, 20.3019, 21.2792,  ..., 21.3435, 21.3082, 21.3041],\n",
      "        [38.9931, 36.4037, 39.0501,  ..., 39.1628, 39.0403, 39.6118],\n",
      "        ...,\n",
      "        [45.1527, 42.5864, 44.8552,  ..., 45.0939, 45.0317, 45.2126],\n",
      "        [29.8938, 28.3030, 29.9864,  ..., 30.0077, 30.0395, 30.1723],\n",
      "        [39.6489, 37.3350, 39.6098,  ..., 39.0894, 39.5937, 39.3437]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[14.2154, 13.6486, 14.2383,  ..., 14.3307, 14.0744, 14.3577],\n",
      "        [10.3060,  9.8839, 10.2889,  ..., 10.5194, 10.5683, 10.4857],\n",
      "        [33.2671, 31.8604, 33.3365,  ..., 33.8103, 33.2683, 33.6999],\n",
      "        ...,\n",
      "        [36.1681, 34.3456, 36.4773,  ..., 36.3030, 36.2299, 36.4249],\n",
      "        [36.1889, 34.3539, 36.0491,  ..., 36.3384, 36.0072, 36.5211],\n",
      "        [40.0661, 37.7993, 40.0153,  ..., 39.9860, 39.2513, 40.4378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[25.3632, 24.0634, 25.3356,  ..., 25.8692, 25.3083, 25.9077],\n",
      "        [21.8570, 20.8570, 21.9826,  ..., 22.3247, 21.9715, 22.2474],\n",
      "        [46.1777, 43.2650, 45.7803,  ..., 46.2387, 45.2802, 46.4927],\n",
      "        ...,\n",
      "        [36.2060, 34.1943, 36.0364,  ..., 36.7629, 35.8613, 36.7523],\n",
      "        [49.2028, 46.3889, 49.0721,  ..., 49.7781, 48.8061, 49.6840],\n",
      "        [23.9627, 22.7497, 24.0472,  ..., 24.5014, 23.9023, 24.5029]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[45.9994, 43.7414, 46.1102,  ..., 46.5826, 45.7635, 47.1875],\n",
      "        [54.4022, 52.0984, 54.2041,  ..., 54.9485, 54.0868, 55.2277],\n",
      "        [42.0298, 39.8097, 41.7190,  ..., 42.4518, 41.6246, 42.6031],\n",
      "        ...,\n",
      "        [47.4961, 45.3086, 47.8694,  ..., 48.2929, 47.5219, 48.6881],\n",
      "        [-6.9747, -6.4792, -6.9491,  ..., -7.1186, -6.7863, -7.1491],\n",
      "        [57.8598, 54.7808, 57.6105,  ..., 58.5034, 57.5369, 58.7256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[53.1273, 50.5123, 53.1909,  ..., 54.2120, 53.1225, 54.4951],\n",
      "        [52.9560, 50.4073, 52.8515,  ..., 54.0553, 52.8460, 54.0074],\n",
      "        [55.1142, 52.8520, 55.2938,  ..., 56.1487, 54.8366, 56.4457],\n",
      "        ...,\n",
      "        [72.2970, 68.5565, 71.6355,  ..., 72.7605, 71.2781, 73.2861],\n",
      "        [61.1811, 58.2928, 61.2541,  ..., 62.2599, 60.8042, 62.5191],\n",
      "        [54.1177, 51.5328, 54.3182,  ..., 55.1829, 53.9809, 55.4763]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[65.2879, 61.8572, 65.3178,  ..., 66.9593, 65.3258, 67.0391],\n",
      "        [67.7830, 64.6871, 68.2630,  ..., 69.7063, 67.5317, 69.3721],\n",
      "        [59.0787, 56.3477, 59.1993,  ..., 60.3942, 59.1525, 60.5492],\n",
      "        ...,\n",
      "        [62.0158, 59.0776, 62.0574,  ..., 63.7626, 61.8351, 64.1475],\n",
      "        [60.5499, 57.9642, 60.5847,  ..., 62.0414, 60.4702, 62.1596],\n",
      "        [60.4904, 57.6231, 60.4997,  ..., 62.1143, 60.6105, 62.4225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[59.9286, 56.7249, 59.9043,  ..., 61.7360, 59.5034, 61.7544],\n",
      "        [68.9124, 65.9064, 68.8796,  ..., 70.7690, 68.7468, 70.8943],\n",
      "        [63.1792, 60.1157, 63.2508,  ..., 64.8397, 62.9842, 65.2815],\n",
      "        ...,\n",
      "        [76.4935, 72.8479, 76.7223,  ..., 78.6316, 76.1929, 79.1226],\n",
      "        [79.2170, 75.4978, 79.1471,  ..., 81.1768, 78.9163, 81.6492],\n",
      "        [74.1949, 70.2018, 73.8130,  ..., 76.0082, 73.6335, 76.0926]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[94.8710, 90.5590, 95.0269,  ..., 98.7714, 94.5585, 98.9503],\n",
      "        [28.5910, 27.4392, 28.7742,  ..., 29.6398, 28.6145, 29.7553],\n",
      "        [76.4751, 72.8443, 76.6545,  ..., 79.1908, 76.6189, 79.5883],\n",
      "        ...,\n",
      "        [74.4087, 70.9037, 74.5145,  ..., 77.1315, 74.2305, 77.3997],\n",
      "        [94.5076, 89.8991, 94.3792,  ..., 97.4763, 94.1377, 97.7618],\n",
      "        [73.5950, 70.2545, 73.7750,  ..., 76.4329, 73.7816, 76.9757]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 70.3170,  66.7395,  70.3024,  ...,  73.7360,  70.0019,  73.9000],\n",
      "        [ 87.1996,  83.1887,  87.0763,  ...,  91.3915,  86.7157,  91.6501],\n",
      "        [103.4414,  98.3226, 103.3250,  ..., 108.5710, 102.9802, 108.6728],\n",
      "        ...,\n",
      "        [ 79.3201,  75.4839,  79.6943,  ...,  83.2691,  79.2933,  83.5179],\n",
      "        [ 97.5428,  92.0988,  97.7811,  ..., 102.4047,  97.1182, 102.3792],\n",
      "        [ 77.9469,  74.0840,  78.0475,  ...,  81.5644,  78.1905,  81.9137]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 85.5135,  81.0803,  85.7608,  ...,  91.1384,  85.4781,  90.8919],\n",
      "        [ 87.1853,  83.0841,  86.9436,  ...,  92.6413,  87.1843,  93.1455],\n",
      "        [ 86.1813,  82.1274,  86.3748,  ...,  92.0082,  86.3219,  92.1932],\n",
      "        ...,\n",
      "        [ 82.3746,  78.3232,  82.5082,  ...,  87.8834,  82.7810,  88.3281],\n",
      "        [100.0753,  95.6692, 100.1227,  ..., 106.8162, 100.4958, 106.7678],\n",
      "        [101.2599,  96.5023, 101.6502,  ..., 107.6620, 101.1880, 108.1359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[88.0686, 84.1491, 88.0819,  ..., 95.9545, 88.9974, 96.0690],\n",
      "        [89.2906, 85.4532, 89.5268,  ..., 97.7365, 89.9715, 97.5326],\n",
      "        [87.3097, 83.6574, 87.8011,  ..., 95.5157, 88.3749, 95.6061],\n",
      "        ...,\n",
      "        [84.2892, 81.3464, 84.6983,  ..., 92.0473, 85.3811, 92.1451],\n",
      "        [91.2450, 87.0493, 91.4897,  ..., 99.4853, 91.9678, 99.6724],\n",
      "        [89.7124, 85.6752, 89.7971,  ..., 97.9800, 90.7527, 98.3797]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[86.7094, 82.9254, 86.4414,  ..., 96.1856, 87.9640, 96.4207],\n",
      "        [80.2648, 77.0019, 80.4539,  ..., 89.3147, 81.4490, 89.8370],\n",
      "        [85.8643, 82.6138, 86.0841,  ..., 95.9609, 87.5702, 95.8295],\n",
      "        ...,\n",
      "        [80.7725, 77.8077, 80.8517,  ..., 89.9679, 81.8550, 90.0193],\n",
      "        [85.1974, 81.7526, 85.5652,  ..., 94.7675, 86.5047, 95.2468],\n",
      "        [80.8634, 77.0771, 80.8201,  ..., 89.7122, 82.0715, 89.9472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[70.3144, 67.6025, 70.3130,  ..., 80.1543, 71.9210, 80.3765],\n",
      "        [72.0534, 69.1736, 71.9019,  ..., 81.6760, 73.5542, 82.0082],\n",
      "        [70.0771, 67.4722, 70.0469,  ..., 79.3408, 71.8100, 79.7533],\n",
      "        ...,\n",
      "        [74.1521, 71.4549, 74.4014,  ..., 84.6737, 76.1525, 84.8027],\n",
      "        [73.5714, 70.6522, 73.4720,  ..., 83.4860, 75.0596, 83.3267],\n",
      "        [68.2689, 65.8417, 68.3707,  ..., 77.6847, 69.9972, 77.8854]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[83.6849, 80.4887, 83.6284,  ..., 96.9086, 86.1510, 97.2036],\n",
      "        [72.4247, 69.8059, 72.6868,  ..., 83.9568, 74.4171, 84.2341],\n",
      "        [59.5073, 57.3196, 59.4818,  ..., 68.9685, 61.4189, 69.0974],\n",
      "        ...,\n",
      "        [57.0107, 55.0655, 57.0879,  ..., 65.9318, 58.7340, 66.1491],\n",
      "        [73.2384, 70.8462, 73.6031,  ..., 84.9012, 75.6030, 85.2177],\n",
      "        [70.3669, 67.8241, 70.6523,  ..., 81.6684, 72.3224, 82.0185]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[76.5715, 73.9562, 76.6220,  ..., 90.4427, 79.5406, 90.6697],\n",
      "        [70.7258, 68.1772, 70.5786,  ..., 83.5381, 73.2207, 83.6529],\n",
      "        [67.3353, 65.0311, 67.3758,  ..., 79.7848, 69.7888, 79.8534],\n",
      "        ...,\n",
      "        [68.4312, 65.9261, 68.2890,  ..., 80.6771, 70.8884, 80.5575],\n",
      "        [74.9037, 72.0146, 75.3009,  ..., 88.6885, 77.7836, 88.8621],\n",
      "        [64.3271, 62.1245, 64.2582,  ..., 75.7864, 66.6007, 76.1053]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 71.2854,  69.0165,  71.1507,  ...,  85.3490,  74.1782,  85.4493],\n",
      "        [ 77.2923,  74.7512,  77.2565,  ...,  92.7238,  80.6493,  92.7131],\n",
      "        [ 91.2455,  88.2703,  91.2302,  ..., 109.8290,  95.2975, 109.8654],\n",
      "        ...,\n",
      "        [ 83.4414,  80.7661,  83.3533,  ...,  99.8973,  86.7360, 100.2020],\n",
      "        [ 73.8099,  71.2543,  73.7184,  ...,  88.7205,  76.7790,  88.4295],\n",
      "        [ 78.4422,  76.1171,  78.3403,  ...,  94.0376,  81.8717,  94.0601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 81.6056,  78.5497,  81.6850,  ...,  99.2932,  85.1147,  99.7085],\n",
      "        [ 76.5001,  73.7586,  76.5512,  ...,  93.0389,  79.8191,  92.8219],\n",
      "        [ 85.3898,  83.0390,  85.4399,  ..., 103.5656,  89.3043, 103.6105],\n",
      "        ...,\n",
      "        [ 79.5487,  76.8177,  79.2874,  ...,  96.6165,  83.0490,  96.7543],\n",
      "        [ 82.8256,  80.2773,  83.0706,  ..., 101.3363,  86.6702, 101.2927],\n",
      "        [ 70.5121,  68.0451,  70.5633,  ...,  85.9433,  73.7637,  85.8973]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 71.7657,  69.4489,  71.7883,  ...,  88.8505,  75.2679,  88.7165],\n",
      "        [ 63.6144,  61.5301,  63.7500,  ...,  78.5033,  66.6626,  78.6076],\n",
      "        [ 75.8247,  73.5464,  75.9461,  ...,  94.1863,  79.5901,  94.1188],\n",
      "        ...,\n",
      "        [ 67.2371,  65.2125,  67.4370,  ...,  83.4311,  70.7496,  83.4666],\n",
      "        [ 85.2262,  82.8035,  85.4697,  ..., 105.6657,  89.7241, 105.4911],\n",
      "        [ 70.1211,  67.8115,  70.0740,  ...,  86.9145,  73.3206,  87.0572]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 72.0976,  69.8446,  72.1456,  ...,  90.3667,  75.8660,  90.2640],\n",
      "        [ 66.6912,  64.7205,  66.8862,  ...,  83.3285,  70.0304,  83.3523],\n",
      "        [ 70.5574,  68.1554,  70.3202,  ...,  88.4020,  74.0974,  88.1808],\n",
      "        ...,\n",
      "        [ 82.9153,  80.1639,  82.9048,  ..., 104.4259,  87.2862, 103.9964],\n",
      "        [ 67.6679,  65.7238,  67.4214,  ...,  84.4859,  71.1979,  84.4194],\n",
      "        [ 84.8516,  81.7585,  84.6643,  ..., 106.6905,  89.4683, 106.7068]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[73.5179, 70.9167, 73.5538,  ..., 93.3437, 77.4013, 92.9723],\n",
      "        [74.6232, 71.6618, 74.2954,  ..., 94.6864, 78.3772, 94.5670],\n",
      "        [62.5707, 60.5894, 62.5747,  ..., 79.0437, 65.7826, 78.7487],\n",
      "        ...,\n",
      "        [71.3677, 68.9397, 71.3420,  ..., 90.5439, 75.2796, 90.4790],\n",
      "        [67.6831, 65.2633, 67.4921,  ..., 85.8083, 71.1669, 85.7739],\n",
      "        [71.8038, 69.1516, 71.8734,  ..., 91.2098, 75.6683, 91.1576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[74.6480, 71.3850, 74.5987,  ..., 95.3297, 78.2101, 95.2577],\n",
      "        [63.3219, 60.7081, 63.1676,  ..., 80.8110, 66.5220, 80.8504],\n",
      "        [77.1095, 74.1067, 77.1829,  ..., 98.5415, 81.3260, 98.5317],\n",
      "        ...,\n",
      "        [75.0026, 71.7334, 74.6258,  ..., 95.7504, 78.6260, 95.7358],\n",
      "        [72.8437, 69.8389, 72.7879,  ..., 93.0885, 76.3928, 92.8762],\n",
      "        [58.6749, 56.5241, 58.6024,  ..., 74.5724, 61.5468, 74.2666]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 74.9283,  71.8069,  75.2732,  ...,  96.7336,  78.9421,  96.3837],\n",
      "        [ 77.8475,  74.7409,  77.8765,  ..., 100.1560,  81.4095, 100.1225],\n",
      "        [ 70.5479,  67.6358,  70.5364,  ...,  90.6631,  73.9684,  90.5691],\n",
      "        ...,\n",
      "        [ 72.2581,  69.1945,  71.8380,  ...,  92.4192,  75.3330,  92.1601],\n",
      "        [ 74.4852,  71.0179,  74.3031,  ...,  95.7424,  77.9332,  95.5279],\n",
      "        [ 68.6883,  65.5687,  68.8119,  ...,  88.4968,  72.1529,  88.3995]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 77.5690,  73.8342,  77.7384,  ..., 100.6503,  80.9958, 100.1824],\n",
      "        [ 74.9766,  71.2196,  74.8867,  ...,  96.8594,  78.1456,  96.7053],\n",
      "        [ 77.7301,  73.7983,  77.8768,  ..., 101.0451,  81.1399, 100.7248],\n",
      "        ...,\n",
      "        [ 71.1436,  67.5903,  71.2336,  ...,  91.8979,  74.3691,  91.9021],\n",
      "        [ 73.8626,  70.3582,  73.9790,  ...,  95.8800,  77.1612,  95.5191],\n",
      "        [ 76.6623,  72.7592,  76.7655,  ...,  99.1268,  79.9497,  99.0363]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 74.0840,  70.1195,  74.3010,  ...,  96.1003,  76.9368,  95.8882],\n",
      "        [ 67.9835,  64.2094,  67.9822,  ...,  88.3273,  70.6634,  87.8255],\n",
      "        [ 75.6623,  71.2671,  75.5797,  ...,  98.0884,  78.5972,  97.8170],\n",
      "        ...,\n",
      "        [ 74.2722,  70.3658,  74.2129,  ...,  96.1353,  77.2420,  95.9121],\n",
      "        [ 71.9491,  68.2539,  71.7599,  ...,  93.2612,  74.7278,  92.8915],\n",
      "        [ 78.3138,  74.2961,  78.3516,  ..., 101.9238,  81.7229, 101.6250]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[75.1049, 70.8574, 75.0783,  ..., 97.6631, 77.5376, 97.2217],\n",
      "        [72.4412, 68.3357, 72.2276,  ..., 94.4800, 75.0862, 94.3238],\n",
      "        [75.4208, 71.1065, 75.4991,  ..., 98.3973, 78.1675, 98.0889],\n",
      "        ...,\n",
      "        [72.7065, 68.1268, 72.4046,  ..., 94.6725, 74.9557, 94.1842],\n",
      "        [71.2449, 66.9093, 71.1433,  ..., 92.8266, 73.5208, 92.4904],\n",
      "        [72.6846, 68.1889, 72.6284,  ..., 94.9188, 75.2770, 94.7134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 78.7569,  74.1645,  78.8820,  ..., 102.8067,  81.1130, 102.6831],\n",
      "        [ 72.4348,  67.9541,  72.4576,  ...,  94.8511,  74.9091,  94.5552],\n",
      "        [ 68.5290,  64.4512,  68.8415,  ...,  89.9648,  70.7742,  89.6837],\n",
      "        ...,\n",
      "        [ 71.2688,  66.9424,  71.3110,  ...,  93.3443,  73.7885,  93.0359],\n",
      "        [ 69.6845,  65.5165,  70.0402,  ...,  91.7643,  72.0575,  91.3797],\n",
      "        [ 75.9368,  71.4866,  76.0377,  ...,  98.5839,  78.2241,  98.5459]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[72.7571, 68.1395, 73.0417,  ..., 95.0334, 74.6281, 94.9142],\n",
      "        [72.1041, 67.2671, 72.1772,  ..., 94.6755, 74.0860, 94.0544],\n",
      "        [73.7810, 68.6727, 73.6340,  ..., 96.5007, 75.8823, 96.1845],\n",
      "        ...,\n",
      "        [71.0909, 66.3843, 70.9428,  ..., 93.1568, 72.6621, 92.9058],\n",
      "        [67.0173, 62.5934, 67.0407,  ..., 87.9575, 68.8912, 87.5633],\n",
      "        [64.1979, 59.8691, 64.1689,  ..., 83.9396, 65.8954, 83.5657]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 79.3268,  73.9037,  79.3343,  ..., 104.2663,  81.4480, 103.8387],\n",
      "        [ 64.2061,  59.9192,  64.4117,  ...,  84.1236,  65.9669,  83.6303],\n",
      "        [ 73.3890,  68.4319,  73.7120,  ...,  95.9263,  75.1764,  95.7728],\n",
      "        ...,\n",
      "        [ 76.4687,  70.9168,  76.2824,  ..., 100.2987,  78.0993,  99.7239],\n",
      "        [ 76.8867,  71.5732,  77.0072,  ..., 101.2648,  78.7628, 100.6663],\n",
      "        [ 73.3967,  68.4855,  73.1972,  ...,  95.7826,  75.2850,  95.3247]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 80.6844,  75.2288,  81.2387,  ..., 106.4511,  82.6617, 105.7830],\n",
      "        [ 75.0107,  69.8608,  75.4479,  ...,  98.9414,  76.4945,  98.2211],\n",
      "        [ 79.7267,  74.2873,  79.9041,  ..., 104.6409,  81.5874, 104.5633],\n",
      "        ...,\n",
      "        [ 73.5859,  68.3486,  73.5977,  ...,  97.0464,  75.4913,  96.4041],\n",
      "        [ 74.0224,  68.8019,  73.9151,  ...,  97.3610,  75.7683,  96.9809],\n",
      "        [ 76.5551,  71.1307,  76.4096,  ..., 100.2904,  78.2087,  99.7275]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 72.1227,  66.3070,  72.0865,  ...,  94.4848,  73.1743,  93.8710],\n",
      "        [ 81.0398,  74.7443,  81.1362,  ..., 106.0560,  81.9500, 105.5562],\n",
      "        [ 73.5461,  68.1452,  73.7010,  ...,  96.4409,  74.6276,  95.9677],\n",
      "        ...,\n",
      "        [ 63.2725,  58.5291,  63.2282,  ...,  82.2448,  64.0961,  81.8955],\n",
      "        [ 75.1658,  69.7472,  75.1733,  ...,  98.2234,  76.3993,  98.0992],\n",
      "        [ 73.8803,  68.1943,  74.0659,  ...,  96.1850,  74.9064,  95.9964]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[72.5111, 66.9913, 72.5013,  ..., 94.7741, 73.2694, 94.2438],\n",
      "        [75.8404, 69.8353, 75.9487,  ..., 98.5123, 76.2682, 98.1454],\n",
      "        [72.4446, 66.5955, 72.4533,  ..., 94.2696, 73.0295, 93.9176],\n",
      "        ...,\n",
      "        [75.4988, 69.2503, 75.4418,  ..., 98.1956, 76.0075, 97.7941],\n",
      "        [73.4637, 67.7015, 73.4188,  ..., 96.0205, 74.2019, 95.6055],\n",
      "        [65.5346, 60.3200, 65.7583,  ..., 84.8815, 66.0758, 84.6642]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 83.0641,  76.6166,  83.1132,  ..., 108.0200,  83.6659, 107.1356],\n",
      "        [ 74.1335,  68.4985,  74.5976,  ...,  96.9683,  74.8089,  96.3893],\n",
      "        [ 76.9169,  70.8727,  77.0423,  ..., 100.0468,  77.5994,  99.5701],\n",
      "        ...,\n",
      "        [ 75.4542,  69.4381,  75.5945,  ...,  97.7839,  75.7037,  97.2520],\n",
      "        [ 74.7411,  68.9811,  74.8694,  ...,  97.4087,  75.0596,  96.8361],\n",
      "        [ 85.2879,  78.8190,  85.3856,  ..., 110.2214,  85.7287, 109.7887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 75.8232,  69.9301,  75.9590,  ...,  98.4035,  75.9686,  97.7598],\n",
      "        [ 85.4350,  79.0282,  85.4770,  ..., 110.1237,  85.4674, 109.1560],\n",
      "        [ 77.9417,  71.9927,  77.8699,  ..., 100.5192,  78.2014,  99.9296],\n",
      "        ...,\n",
      "        [ 81.2550,  74.7524,  81.4210,  ..., 104.6516,  81.1918, 104.2050],\n",
      "        [ 78.9519,  72.9560,  78.7639,  ..., 102.5118,  79.1089, 101.8840],\n",
      "        [ 80.7798,  74.6128,  81.0228,  ..., 104.9040,  81.2704, 104.1301]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[72.0193, 66.5296, 72.2049,  ..., 93.6112, 72.2998, 92.9592],\n",
      "        [74.6167, 68.9886, 74.9613,  ..., 96.5080, 74.8415, 95.9104],\n",
      "        [73.1798, 67.6382, 73.6957,  ..., 95.1471, 73.3435, 94.7435],\n",
      "        ...,\n",
      "        [75.0742, 69.5854, 75.5349,  ..., 97.5683, 75.5663, 97.1733],\n",
      "        [74.7962, 69.3120, 75.0653,  ..., 97.2133, 75.1971, 96.7940],\n",
      "        [71.3774, 66.0694, 71.3867,  ..., 92.5778, 71.6207, 92.1765]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[69.7697, 64.4632, 69.9372,  ..., 90.4406, 69.7518, 89.9130],\n",
      "        [71.8359, 66.3500, 71.8669,  ..., 93.1749, 71.9232, 92.4362],\n",
      "        [70.5923, 65.2901, 70.4990,  ..., 91.0938, 70.5250, 90.4337],\n",
      "        ...,\n",
      "        [69.9947, 64.8375, 69.9289,  ..., 90.7503, 70.0730, 89.8782],\n",
      "        [69.6443, 64.4146, 69.7227,  ..., 90.1757, 69.5867, 89.5635],\n",
      "        [72.8489, 67.5854, 72.9235,  ..., 94.3474, 72.9342, 93.8022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[74.2125, 68.4117, 74.5087,  ..., 96.0307, 74.2162, 95.2563],\n",
      "        [72.5621, 67.1254, 72.6248,  ..., 93.7678, 72.7289, 92.9534],\n",
      "        [74.5291, 68.9536, 74.3329,  ..., 95.9743, 74.5807, 95.5270],\n",
      "        ...,\n",
      "        [70.1984, 64.7458, 70.2952,  ..., 91.1633, 70.5851, 90.5119],\n",
      "        [71.1903, 65.7940, 71.1774,  ..., 92.5820, 71.4824, 91.8403],\n",
      "        [70.0807, 64.9258, 70.1881,  ..., 90.6382, 70.5447, 89.9770]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 75.0042,  69.6606,  75.4617,  ...,  97.4834,  75.6533,  96.6784],\n",
      "        [ 74.5167,  69.2934,  74.9904,  ...,  96.5592,  75.0519,  95.6823],\n",
      "        [ 74.1625,  68.7539,  74.2774,  ...,  95.5014,  74.4281,  94.8670],\n",
      "        ...,\n",
      "        [ 73.0249,  67.7101,  73.4551,  ...,  94.6404,  73.6906,  94.0817],\n",
      "        [ 80.7602,  74.9324,  81.0638,  ..., 104.1797,  81.1677, 103.7900],\n",
      "        [ 76.0405,  70.2420,  76.0423,  ...,  97.8705,  76.3799,  97.2929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 76.2497,  71.0895,  76.2051,  ...,  97.7157,  77.1693,  97.1591],\n",
      "        [ 76.2356,  71.1215,  76.3927,  ...,  98.1366,  76.9858,  97.6454],\n",
      "        [ 76.5916,  71.1798,  76.6984,  ...,  98.7303,  77.1947,  98.0564],\n",
      "        ...,\n",
      "        [ 74.7066,  69.4405,  74.9699,  ...,  95.9438,  75.3330,  95.3499],\n",
      "        [ 76.4594,  70.9569,  76.6755,  ...,  98.3936,  77.1287,  97.8856],\n",
      "        [ 79.1029,  73.4013,  79.3113,  ..., 102.0380,  79.8058, 101.1527]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 79.9040,  74.4134,  80.1353,  ..., 102.7813,  80.9486, 101.9801],\n",
      "        [ 74.2925,  69.3466,  74.5190,  ...,  94.9639,  74.7738,  94.3308],\n",
      "        [ 85.1471,  79.6003,  85.2681,  ..., 109.2541,  86.0041, 108.3591],\n",
      "        ...,\n",
      "        [ 76.1533,  70.9115,  76.4724,  ...,  97.2742,  76.7231,  96.5633],\n",
      "        [ 75.8875,  70.5640,  75.8275,  ...,  96.9570,  76.3374,  96.3779],\n",
      "        [ 82.9844,  76.8954,  83.2002,  ..., 105.7392,  83.5120, 105.1996]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 74.1012,  69.3241,  74.1923,  ...,  94.8759,  74.7751,  94.3213],\n",
      "        [ 76.5757,  71.5091,  76.9682,  ...,  97.8304,  77.3912,  97.2732],\n",
      "        [ 71.8438,  67.0877,  72.0085,  ...,  91.8174,  72.6133,  90.8258],\n",
      "        ...,\n",
      "        [ 82.0224,  76.6426,  82.7471,  ..., 104.8788,  82.6329, 104.0478],\n",
      "        [ 70.5517,  65.9030,  70.5621,  ...,  89.4607,  70.9087,  88.4124],\n",
      "        [ 79.5522,  74.4308,  79.7957,  ..., 101.5008,  80.0585, 100.7279]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[77.1344, 72.3001, 77.2476,  ..., 97.8972, 78.1477, 97.2881],\n",
      "        [69.1137, 64.8023, 69.2473,  ..., 87.6367, 69.7329, 86.9383],\n",
      "        [67.9979, 63.6457, 68.0135,  ..., 86.3611, 68.7692, 85.6490],\n",
      "        ...,\n",
      "        [77.6319, 72.5381, 77.7701,  ..., 97.9425, 78.1678, 97.5500],\n",
      "        [71.3307, 66.9674, 71.4289,  ..., 90.5521, 72.0168, 89.6724],\n",
      "        [71.1475, 66.7438, 71.2120,  ..., 90.0684, 71.9658, 89.2378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[73.3241, 68.8536, 73.3029,  ..., 92.8441, 74.2714, 91.9731],\n",
      "        [70.6403, 66.3328, 70.8938,  ..., 89.4885, 71.7177, 88.8898],\n",
      "        [72.9374, 68.4536, 73.2366,  ..., 92.7544, 74.0624, 91.8927],\n",
      "        ...,\n",
      "        [75.5498, 71.2417, 75.8145,  ..., 95.6975, 76.5647, 94.7878],\n",
      "        [72.6799, 68.3879, 72.9357,  ..., 91.7063, 73.4082, 90.9314],\n",
      "        [70.1480, 65.9751, 70.1855,  ..., 88.7782, 71.0150, 88.0542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 79.3178,  74.5237,  79.7129,  ...,  99.9815,  80.3671,  99.2531],\n",
      "        [ 75.7717,  71.4921,  76.0114,  ...,  95.6057,  77.1000,  94.7612],\n",
      "        [ 88.4827,  83.2558,  88.6504,  ..., 111.9546,  89.7114, 111.0110],\n",
      "        ...,\n",
      "        [ 68.5111,  64.4694,  68.5117,  ...,  86.1124,  69.3183,  85.5027],\n",
      "        [ 77.1241,  73.0467,  77.4324,  ...,  97.3523,  78.5267,  96.4908],\n",
      "        [ 68.4368,  64.6759,  68.6623,  ...,  86.2254,  69.7609,  85.7483]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[73.7597, 69.7005, 73.8790,  ..., 92.6711, 74.9835, 92.2416],\n",
      "        [75.7625, 71.4570, 75.8180,  ..., 95.1332, 77.4663, 94.4902],\n",
      "        [72.8391, 68.8856, 72.9783,  ..., 91.7077, 74.2247, 90.7730],\n",
      "        ...,\n",
      "        [77.3467, 72.8512, 77.4552,  ..., 96.9644, 78.8622, 96.5396],\n",
      "        [75.3637, 71.1104, 75.1784,  ..., 94.6497, 76.5564, 93.9387],\n",
      "        [71.6807, 67.7562, 71.9198,  ..., 90.4170, 73.3493, 89.6213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[77.5652, 72.7558, 77.8091,  ..., 97.2152, 79.0179, 96.3357],\n",
      "        [67.4344, 63.6927, 67.4091,  ..., 84.1838, 69.1017, 83.7453],\n",
      "        [76.7120, 72.7471, 76.9385,  ..., 96.2402, 78.5097, 95.7207],\n",
      "        ...,\n",
      "        [72.8696, 69.0604, 73.1124,  ..., 91.9662, 74.8804, 91.3992],\n",
      "        [72.1977, 68.4249, 72.3927,  ..., 90.6855, 74.3306, 90.3623],\n",
      "        [75.9967, 72.1230, 76.2021,  ..., 95.1610, 77.7858, 94.6677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[71.0652, 67.4284, 71.2162,  ..., 89.0023, 72.8072, 88.2753],\n",
      "        [74.6654, 70.6430, 74.6492,  ..., 93.4558, 77.1194, 92.7572],\n",
      "        [72.1482, 68.4185, 72.1339,  ..., 90.5080, 74.5371, 89.7636],\n",
      "        ...,\n",
      "        [72.7224, 68.7637, 72.9193,  ..., 91.2339, 75.0536, 90.5631],\n",
      "        [73.5253, 69.5632, 73.5369,  ..., 92.1641, 75.5690, 91.3972],\n",
      "        [69.5805, 65.7633, 69.6920,  ..., 87.2625, 71.6252, 86.6339]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[ 82.2246,  77.9202,  82.0778,  ..., 102.6823,  84.6921, 101.9932],\n",
      "        [ 70.8725,  67.2089,  70.9380,  ...,  88.1685,  72.9769,  87.7638],\n",
      "        [ 94.0733,  88.6020,  93.9942,  ..., 117.2108,  96.7078, 116.5808],\n",
      "        ...,\n",
      "        [ 79.9317,  75.9808,  80.4256,  ..., 100.3615,  82.5215,  99.5572],\n",
      "        [ 74.0832,  70.3643,  74.2486,  ...,  93.0073,  76.7326,  92.3796],\n",
      "        [ 73.6235,  69.5969,  73.7520,  ...,  91.6968,  75.9832,  91.1345]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[73.1666, 68.9210, 72.8105,  ..., 90.7728, 75.0074, 90.2553],\n",
      "        [75.8031, 71.7681, 75.7268,  ..., 94.7501, 78.3046, 94.3573],\n",
      "        [77.2798, 72.9077, 77.3058,  ..., 96.8666, 79.7938, 96.2244],\n",
      "        ...,\n",
      "        [71.3644, 67.4654, 71.7233,  ..., 89.2266, 73.5120, 88.8573],\n",
      "        [75.1427, 71.3288, 75.1470,  ..., 94.0274, 77.8719, 93.3891],\n",
      "        [74.3356, 70.2701, 74.3022,  ..., 92.7876, 76.7350, 92.1102]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[71.9660, 68.0485, 71.9070,  ..., 89.9362, 74.3802, 89.1947],\n",
      "        [73.8548, 69.9170, 73.9563,  ..., 92.5703, 76.3961, 92.1261],\n",
      "        [69.8505, 65.7586, 69.6798,  ..., 87.0842, 72.0505, 86.6769],\n",
      "        ...,\n",
      "        [73.8502, 69.7657, 73.5585,  ..., 91.8719, 75.8429, 91.3417],\n",
      "        [70.8101, 66.8653, 70.9818,  ..., 88.2940, 73.0603, 87.6444],\n",
      "        [72.4701, 68.3331, 72.5185,  ..., 90.5335, 74.9056, 89.9049]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[72.1462, 68.2784, 72.2149,  ..., 90.3576, 74.8742, 89.6795],\n",
      "        [76.9187, 72.5629, 77.0254,  ..., 95.7029, 79.8020, 95.3765],\n",
      "        [73.0755, 69.0519, 73.0803,  ..., 91.4176, 75.8731, 90.9715],\n",
      "        ...,\n",
      "        [75.6908, 71.4739, 75.5325,  ..., 94.1684, 78.2772, 93.7147],\n",
      "        [73.7712, 69.4980, 73.6143,  ..., 92.0626, 76.6829, 91.6159],\n",
      "        [70.8893, 66.5108, 70.9786,  ..., 88.2030, 73.1064, 87.6403]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[73.5839, 69.6447, 73.4201,  ..., 91.8720, 76.4822, 91.2663],\n",
      "        [70.1941, 66.6316, 70.0504,  ..., 87.5823, 72.7818, 87.3267],\n",
      "        [69.7443, 65.7898, 69.7391,  ..., 87.2501, 72.4223, 86.7832],\n",
      "        ...,\n",
      "        [80.0059, 75.7711, 80.1168,  ..., 99.8528, 83.1274, 99.1883],\n",
      "        [75.0091, 71.1302, 75.2565,  ..., 93.7611, 78.1122, 93.5152],\n",
      "        [76.0545, 71.9303, 76.0425,  ..., 94.5120, 79.0191, 94.2705]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "output shape :  torch.Size([63, 48])\n",
      "tensor([[ 72.0067,  68.3691,  72.0567,  ...,  89.8228,  74.9218,  89.2894],\n",
      "        [ 77.4499,  73.1497,  77.1980,  ...,  96.3369,  80.2424,  95.9989],\n",
      "        [ 75.2153,  71.0291,  75.3209,  ...,  93.7768,  77.6718,  93.3972],\n",
      "        ...,\n",
      "        [ 81.9757,  77.3671,  81.7203,  ..., 101.8848,  84.9691, 101.6351],\n",
      "        [ 81.1492,  76.4653,  81.0691,  ..., 101.2017,  84.2324, 100.8373],\n",
      "        [ 76.9247,  72.8985,  77.1977,  ...,  96.0708,  79.9997,  95.5534]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "train (3775) Loss: 1055.4988 Acc: 0.0000 Elapsed time: 1m 54s\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-3859.1975, -3689.2646, -3978.3201,  ..., -4027.2288, -3890.0735,\n",
      "         -3990.8135],\n",
      "        [-3655.5312, -3494.6265, -3768.1267,  ..., -3814.3088, -3684.2288,\n",
      "         -3779.4993],\n",
      "        [-5109.7432, -4879.6714, -5267.3755,  ..., -5317.5024, -5143.5693,\n",
      "         -5272.3110],\n",
      "        ...,\n",
      "        [-5105.2051, -4875.3560, -5262.7642,  ..., -5312.7075, -5139.0234,\n",
      "         -5267.5898],\n",
      "        [-3097.0906, -2958.4155, -3193.4236,  ..., -3191.2927, -3114.6326,\n",
      "         -3166.4219],\n",
      "        [-2288.6770, -2177.6672, -2367.6013,  ..., -2267.0569, -2278.8582,\n",
      "         -2256.5688]], device='cuda:0')\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-6200.3574, -5921.0122, -6391.6885,  ..., -6451.8818, -6241.1270,\n",
      "         -6397.1113],\n",
      "        [-6665.2305, -6364.7603, -6871.3203,  ..., -6934.9395, -6709.2144,\n",
      "         -6876.4131],\n",
      "        [-3136.9910, -2996.6824, -3234.5530,  ..., -3232.9922, -3154.8645,\n",
      "         -3207.7915],\n",
      "        ...,\n",
      "        [-3134.0183, -2993.9031, -3231.4983,  ..., -3229.5579, -3151.7517,\n",
      "         -3204.3845],\n",
      "        [-6671.9678, -6371.3511, -6877.9839,  ..., -6943.6382, -6716.1997,\n",
      "         -6884.8398],\n",
      "        [-4799.3657, -4575.6069, -4951.6924,  ..., -4942.7925, -4821.6504,\n",
      "         -4906.6831]], device='cuda:0')\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-6407.2236, -6123.9717, -6605.3638,  ..., -6679.5293, -6456.9258,\n",
      "         -6619.4766],\n",
      "        [-2621.1487, -2494.2544, -2711.3723,  ..., -2595.5256, -2609.9929,\n",
      "         -2583.3286],\n",
      "        [-3271.5457, -3127.3406, -3372.4292,  ..., -3415.5547, -3297.3518,\n",
      "         -3384.4473],\n",
      "        ...,\n",
      "        [-3712.4089, -3543.1938, -3830.5500,  ..., -3833.1042, -3734.6069,\n",
      "         -3802.9771],\n",
      "        [-4565.0825, -4363.6533, -4706.1421,  ..., -4761.5034, -4601.0781,\n",
      "         -4718.5366],\n",
      "        [-3345.1648, -3197.7529, -3448.3145,  ..., -3493.5347, -3371.9065,\n",
      "         -3461.7446]], device='cuda:0')\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-5884.9355, -5624.8735, -6067.0527,  ..., -6137.0991, -5931.0278,\n",
      "         -6082.0400],\n",
      "        [-3318.0740, -3169.5874, -3421.2844,  ..., -3420.6636, -3336.9890,\n",
      "         -3393.8286],\n",
      "        [-5951.2261, -5688.4868, -6135.2690,  ..., -6207.7236, -5998.0986,\n",
      "         -6151.9365],\n",
      "        ...,\n",
      "        [-3641.3093, -3481.1187, -3753.4519,  ..., -3800.0354, -3670.0190,\n",
      "         -3765.3340],\n",
      "        [-3256.2966, -3113.2148, -3356.4705,  ..., -3400.5120, -3282.3459,\n",
      "         -3369.3833],\n",
      "        [-2582.3289, -2457.1606, -2671.2693,  ..., -2556.2864, -2571.1128,\n",
      "         -2544.3137]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-3628.9731, -3469.0698, -3740.7246,  ..., -3786.3989, -3657.3596,\n",
      "         -3751.8135],\n",
      "        [-6654.5039, -6354.7271, -6859.8711,  ..., -6925.9854, -6698.6895,\n",
      "         -6867.2666],\n",
      "        [-5259.5054, -5027.2939, -5422.1616,  ..., -5486.0337, -5301.0635,\n",
      "         -5436.6338],\n",
      "        ...,\n",
      "        [-5948.8140, -5680.5894, -6132.4907,  ..., -6188.4688, -5987.6255,\n",
      "         -6136.0430],\n",
      "        [-2918.6970, -2785.6021, -3011.5876,  ..., -3014.5237, -2935.9636,\n",
      "         -2990.8594],\n",
      "        [-3230.1770, -3088.1504, -3329.6023,  ..., -3372.4163, -3255.8643,\n",
      "         -3341.6060]], device='cuda:0')\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[-2681.1653, -2550.9653, -2773.7803,  ..., -2654.1323, -2669.5144,\n",
      "         -2641.8223],\n",
      "        [-4686.9995, -4468.5288, -4835.7026,  ..., -4827.9546, -4708.9624,\n",
      "         -4792.6274],\n",
      "        [-5946.3687, -5683.7153, -6130.3154,  ..., -6201.6465, -5993.0107,\n",
      "         -6145.9629],\n",
      "        ...,\n",
      "        [-3563.2869, -3406.5544, -3673.0151,  ..., -3718.6460, -3591.3877,\n",
      "         -3684.6816],\n",
      "        [-5252.9282, -5021.6255, -5415.0815,  ..., -5484.3105, -5295.4258,\n",
      "         -5434.6826],\n",
      "        [-6236.0161, -5954.8735, -6428.5571,  ..., -6488.5137, -6277.0117,\n",
      "         -6433.5566]], device='cuda:0')\n",
      "output shape :  torch.Size([36, 48])\n",
      "tensor([[-3573.5310, -3415.8594, -3683.7903,  ..., -3730.0891, -3601.7212,\n",
      "         -3696.2412],\n",
      "        [-5912.8003, -5651.6226, -6095.7061,  ..., -6166.6562, -5959.1826,\n",
      "         -6111.2817],\n",
      "        [-3573.3975, -3413.2803, -3684.5837,  ..., -3682.4417, -3593.4500,\n",
      "         -3653.5842],\n",
      "        ...,\n",
      "        [-4689.8633, -4483.1099, -4834.6997,  ..., -4893.6367, -4727.2334,\n",
      "         -4849.4023],\n",
      "        [-6255.1313, -5973.1294, -6448.2690,  ..., -6508.3599, -6296.2617,\n",
      "         -6453.2451],\n",
      "        [-6197.9658, -5918.5430, -6389.3276,  ..., -6448.7739, -6238.6875,\n",
      "         -6394.1548]], device='cuda:0')\n",
      "val (420) Loss: 22216025.9619 Acc: 0.0000 Elapsed time: 2m 4s\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "output shape :  torch.Size([64, 48])\n",
      "tensor([[71.5412, 67.7611, 71.4714,  ..., 89.1320, 74.6470, 89.0132],\n",
      "        [66.6956, 63.0665, 66.7393,  ..., 83.1373, 69.5636, 82.7814],\n",
      "        [74.0695, 70.0946, 73.9722,  ..., 92.3409, 77.0730, 91.8406],\n",
      "        ...,\n",
      "        [78.6596, 74.5813, 78.6558,  ..., 98.0973, 82.0175, 97.8337],\n",
      "        [74.0298, 69.9617, 74.1540,  ..., 92.3067, 77.1792, 92.1890],\n",
      "        [70.9524, 67.2244, 70.9126,  ..., 88.3653, 74.0941, 88.1529]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "since = time.time()\n",
    "X_train, X_val, y_train, y_val = train_test_split(imgs, keypoints, test_size=1/num_splits, random_state=42)\n",
    "train_data = Dataset(train_dir, X_train, y_train, data_transforms=A_transforms, class_labels=class_labels, phase='train')\n",
    "val_data = Dataset(train_dir, X_val, y_val, data_transforms=A_transforms, class_labels=class_labels, phase='val')\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data_utils.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hists = train_model(\n",
    "    model_ft, dataloaders, criterion, optimizer_ft,\n",
    "    num_epochs=num_epochs,  is_inception=(model_name==\"inception\"))\n",
    "weight_path = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\", f\"baseline_{model_name}_{model_ver}.pth\")\n",
    "torch.save(model_ft.state_dict(), weight_path)\n",
    "time_elapsed = time.time() - since\n",
    "print('Elapsed time: {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = f'{prefix}/data/test_imgs'\n",
    "test_dir = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"test_imgs\")\n",
    "test_imgs = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data_utils.Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "    def __init__(self, data_dir, imgs, phase, data_transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.imgs = imgs\n",
    "        self.phase = phase\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.imgs[idx]\n",
    "        # Read an image with OpenCV\n",
    "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
    "\n",
    "        if self.data_transforms:\n",
    "            augmented = self.data_transforms[self.phase](image=img)\n",
    "            img = augmented['image']\n",
    "        return filename, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "test_data = TestDataset(test_dir, test_imgs, data_transforms=A_transforms, phase='test')\n",
    "test_loader = data_utils.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "files = []\n",
    "with torch.no_grad():\n",
    "    for filenames, inputs in test_loader:\n",
    "        predictions = list(model_ft(inputs.to(device)).cpu().numpy())\n",
    "        files.extend(filenames)\n",
    "        for prediction in predictions:\n",
    "            all_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "for i in range(all_predictions.shape[0]):\n",
    "    all_predictions[i, [2*j for j in range(num_classes//2)]] /= input_w / 1920\n",
    "    all_predictions[i, [2*j + 1 for j in range(num_classes//2)]] /= input_h / 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"sample_submission.csv\")\n",
    "df_sub = pd.read_csv(path)\n",
    "df = pd.DataFrame(columns=df_sub.columns)\n",
    "df['image'] = files\n",
    "df.iloc[:, 1:] = all_predictions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"C:\\\\Users\\\\hwanseung\\\\Desktop\\\\\", \"open\", \"1. open\",\"efficient.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
